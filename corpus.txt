****************************** #1 ******************************
StackOverflow URL: https://stackoverflow.com/questions/1846405

comment sentences(s):
So  when  building  your  query  ,  use  LOWERCASE  prefix  in  order  to  have  hits  :

code statement(s):
query.Add(new PrefixQuery(new Term("B","lala")),BooleanClause.Occur.MUST)
query.Add(new PrefixQuery(new Term("C","dodo")),BooleanClause.Occur.MUST)

****************************** #2 ******************************
StackOverflow URL: https://stackoverflow.com/questions/1742245

comment sentences(s):
In  order  to  know  for  sure  ,  use  the  explain() function  to  debug  the  scores  .

code statement(s):
explain(query,scoreDoc.doc)

****************************** #3 ******************************
StackOverflow URL: https://stackoverflow.com/questions/1438071

comment sentences(s):
  When  you  are  getting  bytes  from  String  ,  you  should  specify  the  encoding  .

code statement(s):
xmlEncoding.GetBytes(s)

****************************** #4 ******************************
StackOverflow URL: https://stackoverflow.com/questions/1438071

comment sentences(s):
  The  third  parameter  in  Write() probabably  refers  to  the  length  of  byte  array  which  you  got  from  GetBytes() .

code statement(s):
Write(xmlEncoding.GetBytes(s),0,s.Length)

****************************** #5 ******************************
StackOverflow URL: https://stackoverflow.com/questions/1433524

comment sentences(s):
each  query ( one  for  the  SearchKey  and  one  for  the  Type  )

code statement(s):
query1=new QueryParser("SearchKey",standardLuceneAnalyzer).Parse("Kansas City*")
query2=new QueryParser("Type",standardLuceneAnalyzer).Parse("Airport")

****************************** #6 ******************************
StackOverflow URL: https://stackoverflow.com/questions/488098

comment sentences(s):
As  Steve  mentioned  ,  you  need  to  use  an  instance  of  IndexReader  and  call  its  DeleteDocuments  method  .

code statement(s):
indexReader.DeleteDocuments(new Term("patient_id",patientID))

****************************** #7 ******************************
StackOverflow URL: https://stackoverflow.com/questions/488098

comment sentences(s):
DeleteDocuments  accepts  either  an  instance  of  a  Term  object  or  Lucene  's  internal  id  of  the  document ( it  is  generally  not  recommended  to  use  the  internal  id  as  it  can  and  will  change  as  Lucene  merges  segments ) .

code statement(s):
DeleteDocuments(new Term("patient_id",patientID))

****************************** #8 ******************************
StackOverflow URL: https://stackoverflow.com/questions/488098

comment sentences(s):
accepts  either  an  instance  of  a  Term  object  or  Lucene  's  internal  id  of  the  document ( it  is  generally  not  recommended  to  use  the  internal  id  as  it  can  and  will  change  as  Lucene  merges  segments  )

code statement(s):
new Term("patient_id",patientID)

****************************** #9 ******************************
StackOverflow URL: https://stackoverflow.com/questions/488098

comment sentences(s):
For  example  ,  in  an  index  of  patients  in  a  doctor  's  office  ,  if  you  had  a  field  called  ``  patient_id  ''  you  could  create  a  term  and  pass  that  as  an  argument  to  DeleteDocuments  .

code statement(s):
DeleteDocuments(new Term("patient_id",patientID))

****************************** #10 ******************************
StackOverflow URL: https://stackoverflow.com/questions/379345

comment sentences(s):
The  following  code  assumes  a1  ,  a2  ,  a3  ,  t1  ,  t2  ,  t3  are  terms  .

code statement(s):
new TermQuery(new Term("Author","a1"))
new TermQuery(new Term("title","t1"))
new TermQuery(new Term("Author","a2"))
new TermQuery(new Term("title","t2"))
new TermQuery(new Term("Author","a3"))
new TermQuery(new Term("title","t3"))

****************************** #11 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3805594

comment sentences(s):
The  relevant  code  line  is  :  That  will  get  the  token  stream  from  the  index  .

code statement(s):
TokenStream stream=TokenSources.getAnyTokenStream(searcher.getIndexReader(),sd.doc,"title",doc,analyzer);


****************************** #12 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3764542

comment sentences(s):
The  search  method  of  the  Searcher  class  has  a  parameter  to  limit  the  number  of  results  returned  for  a  query  .

code statement(s):
searcher.search(query,20)

****************************** #13 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3376937

comment sentences(s):
One  option  is  of  course  to  remove  a  document  and  then  to  add  the  updated  version  of  the  document  .

code statement(s):
UpdateDocument(new Term("patient_id",document.Get("patient_id")),document)

****************************** #14 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3376937

comment sentences(s):
Alternatively  you  can  also  use  the  UpdateDocument() method  of  the  IndexWriter  class  :  This  of  course  requires  you  to  have  a  mechanism  by  which  you  can  locate  the  document  you  want  to  update ( ``  patient_id  ''  in  this  example ) .

code statement(s):
writer.UpdateDocument(new Term("patient_id",document.Get("patient_id")),document)

****************************** #15 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3376937

comment sentences(s):
a  mechanism  by  which  you  can  locate  the  document  you  want  to  update ( ``  patient_id  ''  in  this  example  )

code statement(s):
UpdateDocument(new Term("patient_id",document.Get("patient_id")),document)

****************************** #16 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3256026

comment sentences(s):
You  can  use  Query.combine() to  OR  queries  together  .

code statement(s):
Query query=termQuery.combine(new Query[]{termQuery,pageQueryRange});


****************************** #17 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3029239

comment sentences(s):
get  the  path  via

code statement(s):
pageContext.getServletContext().getRealPath("/")

****************************** #18 ******************************
StackOverflow URL: https://stackoverflow.com/questions/2589041

comment sentences(s):
The  top  docs  collector

code statement(s):
TopDocs topDocs=searcher.search(qry,10);


****************************** #19 ******************************
StackOverflow URL: https://stackoverflow.com/questions/2304831

comment sentences(s):
If  you  are  using  projections  you  can  do  this  by  having  one  of  the  properties  that  you  are  projecting  to  be  a  ProjectionConstants.SCORE  reference  .

code statement(s):
SetProjection("FirstName","LastName",ProjectionConstants.SCORE)

****************************** #20 ******************************
StackOverflow URL: https://stackoverflow.com/questions/5528005

comment sentences(s):
Build  your  search  query  using  a  BooleanQuery  ,  add  a  PrefixQuery  for  your  path  ,  and  use  QueryParser  for  the  user  provided  search  string  .

code statement(s):
Add(new PrefixQuery("Path","questions\\text\\testing\\"),BooleanClause.Occur.MUST)

****************************** #21 ******************************
StackOverflow URL: https://stackoverflow.com/questions/5528005

comment sentences(s):
Build  your  search  query  using  a  BooleanQuery

code statement(s):
query=new BooleanQuery()

****************************** #22 ******************************
StackOverflow URL: https://stackoverflow.com/questions/5528005

comment sentences(s):
a  PrefixQuery  for  your  path

code statement(s):
new PrefixQuery("Path","questions\\text\\testing\\")

****************************** #23 ******************************
StackOverflow URL: https://stackoverflow.com/questions/5423557

comment sentences(s):
changed  from  a  Formatter  to  a  SimpleFormatter

code statement(s):
SimpleHTMLFormatter formatter=new SimpleHTMLFormatter(config.HighlightFormatterPrefix,config.HighlightFormatterSuffix);


****************************** #24 ******************************
StackOverflow URL: https://stackoverflow.com/questions/5104468

comment sentences(s):
For  Lucene  3.0.3 ( current ) ,  you  need  to  construct  the  StandardAnalyzer  with  an  empty  set  of  stop  words  ,  using  something  like  this  :

code statement(s):
new StandardAnalyzer(LUCENE_30,Collections.emptySet())

****************************** #25 ******************************
StackOverflow URL: https://stackoverflow.com/questions/4977601

comment sentences(s):
If  so  ,  you  can  bypass  it  and  create  a  Query  ,  e.g.  ,  a  TermQuery  ,  manually  .

code statement(s):
Query q=new TermQuery(new Term("field","I+D"));


****************************** #26 ******************************
StackOverflow URL: https://stackoverflow.com/questions/4490916

comment sentences(s):
You  can  use  a  QueryWrapperFilter  to  turn  an  arbitrary  query  into  a  filter  .

code statement(s):
Filter myFilter=new CachingWrapperFilter(new QueryWrapperFilter(bq));


****************************** #27 ******************************
StackOverflow URL: https://stackoverflow.com/questions/4490916

comment sentences(s):
And  you  can  use  a  CachingWrapperFilter  to  cache  any  filter  .

code statement(s):
Filter myFilter=new CachingWrapperFilter(new QueryWrapperFilter(bq));


****************************** #28 ******************************
StackOverflow URL: https://stackoverflow.com/questions/7482784

comment sentences(s):
As  the  second  document  you  added  with  the  same  id  does  not  have  the  price  field  ,  it  wo  n't  be  added  and  you  wont  find  it  the  index  .

code statement(s):
addField("price",new Float(10))

****************************** #29 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6664502

comment sentences(s):
Try  using  :  i.e.  escape  the  search  text  before  building  your  query  .

code statement(s):
escapedSearchText=QueryParser.Escape(searchText)

****************************** #30 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6028374

comment sentences(s):
The  way  to  do  filtering  in  Search  is  via  FullTextFilters  .

code statement(s):
fullTextQuery.enableFullTextFilter("version")

****************************** #31 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6028374

comment sentences(s):
You  would  probably  need  another  query  to  determine  the  max  values  .

code statement(s):
fullTextQuery.enableFullTextFilter("version").setParameter("max",1001)

****************************** #32 ******************************
StackOverflow URL: https://stackoverflow.com/questions/10521875

comment sentences(s):
You  make  2  queries  ,  one  for  each  complete  search  statement  ,  and  then  add  them  together  with  the  ``  SHOULD  ''  operator  .

code statement(s):
add(bq1,BooleanClause.Occur.SHOULD)
add(bq2,BooleanClause.Occur.SHOULD)

****************************** #33 ******************************
StackOverflow URL: https://stackoverflow.com/questions/10453973

comment sentences(s):
When  you  build  your  IndexWriter  for  the  delete  method  like  that  :  You  are  specifying  true  for  the  create  parameter  ,  which  overwrites  the  existing  index  with  an  empty  one  ,  deleting  all  your  documents  .

code statement(s):
new IndexWriter(directory,analyzar,true,IndexWriter.MaxFieldLength.LIMITED)

****************************** #34 ******************************
StackOverflow URL: https://stackoverflow.com/questions/10301564

comment sentences(s):
You  only  have  to  enable  the  support  for  leading  wildcards  on  your  query  parser  :  Take  care  :  Leading  wildcards  might  slow  your  search  down  .

code statement(s):
parser.setAllowLeadingWildcard(true)

****************************** #35 ******************************
StackOverflow URL: https://stackoverflow.com/questions/10301564

comment sentences(s):
leading  wildcards

code statement(s):
setAllowLeadingWildcard(true)

****************************** #36 ******************************
StackOverflow URL: https://stackoverflow.com/questions/10259944

comment sentences(s):
You  should  escape  the  double  quote  and  other  special  characters  via  As  the  QueryParser.escape  Javadoc  suggested  ,  <blockquote>  Returns  a  String  where  those  characters  that  QueryParser  expects  to  be  escaped  are  escaped  by  a  preceding  '  \  '  .

code statement(s):
Query query=parser.parse(QueryParser.escape(parsedReview));


****************************** #37 ******************************
StackOverflow URL: https://stackoverflow.com/questions/10259944

comment sentences(s):
<blockquote>  Returns  a  String  where  those  characters  that  QueryParser  expects  to  be  escaped  are  escaped  by  a  preceding  '  \  '

code statement(s):
QueryParser.escape(parsedReview)

****************************** #38 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9986841

comment sentences(s):
I  want  to  find  out  if  a  particular  item  was  active  between  a  start  and  an  end  date  .

code statement(s):
activeTodayFilter.Add(new BooleanClause(lowerRange,BooleanClause.Occur.MUST))
activeTodayFilter.Add(new BooleanClause(upperRange,BooleanClause.Occur.MUST))

****************************** #39 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9738822

comment sentences(s):
If  you  give  it  an  empty  Term  for  a  field  ,  it  will  return  a  TermEnum  containing  all  the  terms  for  that  field  .

code statement(s):
TermEnum terms=indexReader.Terms(new Term("category"));


****************************** #40 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9099817

comment sentences(s):
I  'll  post  the  exact  code  snippet  I  used  to  test  this  ,  comparing  it  to  your  code  will  maybe  help  you  finding  whats  wrong  .

code statement(s):
document.GetField("text").SetValue("another doc")

****************************** #41 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13415105

comment sentences(s):
In  this  version  ,  spellChecker.IndexDictionary() function  needs  3  arguments  :  config  is  an  IndexWriterConfig  object  .

code statement(s):
spellChecker.indexDictionary(new PlainTextDictionary(new File("fulldictionary00.txt")),config,false)

****************************** #42 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13245580

comment sentences(s):
You  have  the  lat  &  lon  from  the  field  ;  now  you  need  to  calculate  the  distance  from  the  center  point  of  the  query  circle  .

code statement(s):
distance(args.getShape().getCenter(),lo1,la1)

****************************** #43 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12863385

comment sentences(s):
I  believe  that  last  line  should  be  :  Since  results  are  numbered  from  0  .

code statement(s):
query.setFirstResult(0).setMaxResults(100)

****************************** #44 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12744085

comment sentences(s):
How  to  use  KStemmer  inside  one  's  code  :  You  will  have  to  split  your  document  contents  to  a  list  of  terms  yourself  .

code statement(s):
stemmer.stem(term,len)

****************************** #45 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12717591

comment sentences(s):
<strong>  Query  of  Custom  Fields  </strong>  Just  use  the  projection  API  :  Using  projections  you  get  to  read  any  field  as  long  as  it  's  STORED  .

code statement(s):
FullTextQuery hibernateQuery=fullTextSession.createFullTextQuery(luceneQuery).setProjection("myField1","myField2");


****************************** #46 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12529270

comment sentences(s):
Have  you  tried  the  IndexSearcher.Search  overload  accepting  a  sort  argument  ?

code statement(s):
searcher.Search(query,null,1,new Sort(sortField))

****************************** #47 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12430865

comment sentences(s):
Searching  for  a  single  country  by  GUID  with  your  code  above  should  work  .

code statement(s):
new FieldQuery("countries",country1GUID)
new FieldQuery("countries",country2GUID)

****************************** #48 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12383955

comment sentences(s):
In  order  too  find  a  phrase  consisting  of  multiple  terms  ,  you  would  need  to  use  PhraseQuery  instead  of  WildcardQuery  .

code statement(s):
phraseQuery.Add(new Term(string - field - name,"very"))
phraseQuery.Add(new Term(string - field - name,"good"))

****************************** #49 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12365245

comment sentences(s):
The  key  is  to  call  <em>  query.setProjection  </em>  with  the  list  of  field  names  you  want  to  retrieve  from  the  index  .

code statement(s):
query.setProjection("field1","field2","field3")

****************************** #50 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
NumericField  documentation  <blockquote>

code statement(s):
NumericField number=new NumericField("number",Field.Store.YES,true);


****************************** #51 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
Note  that  you  must  also  specify  a  congruent  value  when  creating  NumericRangeQuery  or  NumericRangeFilter  .

code statement(s):
NumericRangeQuery rangeQ=NumericRangeQuery.NewIntRange("number",1,2,true,true);


****************************** #52 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11775614

comment sentences(s):
You  need  to  call  these  two  functions  to  set  the  highlighter  tags  .  .

code statement(s):
builder.setHighlighterPreTags("&lt;pre&gt;").setHighlighterPostTags("&lt;/pre&gt;")

****************************** #53 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11269749

comment sentences(s):
Here  is  why  I  assume  you  want  to  find  a  document  that  has  the  terms  below  :  abc  ,1,2,3  ,  def  ,1,2,3,4,5  ,  ghi  Both  queries  will  find  the  document  above  .

code statement(s):
Query queryToBeExecuted=new SpanNearQuery(new SpanQuery[]{spanNear,new SpanTermQuery(new Term(FIELD,"ghi"))},5,true);


****************************** #54 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11269749

comment sentences(s):
You  can  use  queryToBeExecuted  query  for  your  search  .

code statement(s):
Query queryToBeExecuted=new SpanNearQuery(new SpanQuery[]{spanNear,new SpanTermQuery(new Term(FIELD,"ghi"))},5,true);


****************************** #55 ******************************
StackOverflow URL: https://stackoverflow.com/questions/16306137

comment sentences(s):
You  can  get  the  FieldInfos  with  AtomicReader.getFieldInfos() .

code statement(s):
for(FieldInfo info : atomicReader.getFieldInfos().iterator())

****************************** #56 ******************************
StackOverflow URL: https://stackoverflow.com/questions/16303616

comment sentences(s):
The  retrieved  document  does  n't  have  the  boost  set  .

code statement(s):
updatedDocument.setBoost(newBoost)

****************************** #57 ******************************
StackOverflow URL: https://stackoverflow.com/questions/16303616

comment sentences(s):
the  boost  set

code statement(s):
setBoost(newBoost)
boostField.setFloatValue(newBoost)

****************************** #58 ******************************
StackOverflow URL: https://stackoverflow.com/questions/15730250

comment sentences(s):
To  handle  your  use  case  ,  it  is  simpler  that  you  already  have  references  to  city-keyword  and  title-keyword  separately  .

code statement(s):
cityQP=new QueryParser(Version.LUCENE_CURRENT,"city",analyzer)
titleQP=new QueryParser(Version.LUCENE_CURRENT,"title",analyzer)

****************************** #59 ******************************
StackOverflow URL: https://stackoverflow.com/questions/15207701

comment sentences(s):
Once  you  get  the  ID  of  the  matching  document  ,  prepare  a  query  for  each  field ( using  the  same  search  keywords ) and  invoke  Explanation.isMatch() for  each  query  :  the  ones  that  yield  true  will  give  you  the  matched  field  .

code statement(s):
Explanation ex=searcher.explain(query,docID);


****************************** #60 ******************************
StackOverflow URL: https://stackoverflow.com/questions/15205970

comment sentences(s):
The  problem  is  you  're  defining  a  <em>  phrase  </em>  Query  ,  you  should  use  <em>  keyword  </em>

code statement(s):
Query q=qb.keyword().onField("myField").matching("12345%SEPERATOR%4").createQuery();


****************************** #61 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14892100

comment sentences(s):
your  int  value

code statement(s):
int value=4711;


****************************** #62 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14683447

comment sentences(s):
use  a  DrillDown  query  on  the  first  query  e.g

code statement(s):
Query q2=DrillDown.query(indexingParams,q,cat);


****************************** #63 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14662777

comment sentences(s):
As  an  example  for  Lucene.Net  2.9.4  g  :  This  generates  a  Lucene.Net.Search.Query  object  that  can  be  used  to  search  for  documents  that  are  similar  to  the  text  passed  into  the  StringReader  object  .

code statement(s):
query=moreLikeThis.Like(new System.IO.StringReader(similarity))

****************************** #64 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14662777

comment sentences(s):
similar  to  the  text  passed  into  the  StringReader  object

code statement(s):
new System.IO.StringReader(similarity)

****************************** #65 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14115465

comment sentences(s):
For  document  retrieval  ,  assuming  you  've  stored  the  field  value  ,  you  should  retrieve  a  text  value  from  the  index  and  convert  it  to  an  integer  .

code statement(s):
myField=doc.GetFieldable("mynumber").StringValue()

****************************** #66 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13963953

comment sentences(s):
`  CreatedAt  '  field

code statement(s):
new SortField("CreatedAt",SortField.LONG,true)

****************************** #67 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13869975

comment sentences(s):
If  you  need  to  search  for  documents  in  which  certain  fields  are  null

code statement(s):
new RangeQuery(FieldName,null,null,true,true)

****************************** #68 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13849227

comment sentences(s):
Add  the  field  several  times  ,  something  like  ...

code statement(s):
Add(new Field("testfield","A"))
Add(new Field("testfield","B"))
Add(new Field("testfield","C"))

****************************** #69 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13620348

comment sentences(s):
MultiFieldQueryParser  allows  you  to  search  for  a  ``  WORD  ''  in  more  then  one  Fileds  with  same  Analyzer  .

code statement(s):
MultiFieldQueryParser.parse("development",new String[]{"title","subject"},new SimpleAnalyzer())

****************************** #70 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13620348

comment sentences(s):
e.g.  it  will  look  for  word  development  in  Field  :  ``  title  ''  and  Field  :  ``  subject  ''

code statement(s):
parse("development",new String[]{"title","subject"},new SimpleAnalyzer())

****************************** #71 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19327067

comment sentences(s):
You  could  also  use  a  query  parser  as  documented  in  the  Hibernate  Search  documentation  ,  Chapter  5  ,  in  Example  5.2

code statement(s):
org.hibernate.search.FullTextQuery fullTextQuery=fullTextSession.createFullTextQuery(luceneQuery,Computer.class);


****************************** #72 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19311975

comment sentences(s):
For  anybody  who  may  need  this  in  the  future  ,  this  will  demonstrate  how  to  do  additional  query  restrictions  with  hibernate  search  .

code statement(s):
query=session.createCriteria(Store.class).createAlias("department","department").add(Restrictions.eq("department.name",category))

****************************** #73 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19216617

comment sentences(s):
Try  creating  a  BooleanQuery  composed  of  TermQuery  objects  ,  combined  with  OR ( BooleanClause.Occur.SHOULD ) .

code statement(s):
booleanQuery.add(term1,BooleanClause.Occur.SHOULD)
booleanQuery.add(term2,BooleanClause.Occur.SHOULD)

****************************** #74 ******************************
StackOverflow URL: https://stackoverflow.com/questions/18133916

comment sentences(s):
user  name

code statement(s):
new Field("userName",userName)

****************************** #75 ******************************
StackOverflow URL: https://stackoverflow.com/questions/18084720

comment sentences(s):
The  Fragmenter  handles  how  the  text  is  split  up ( or  fragmented ) .

code statement(s):
setTextFragmenter(new NullFragmenter())

****************************** #76 ******************************
StackOverflow URL: https://stackoverflow.com/questions/18084720

comment sentences(s):
The  NullFragmenter  is  intended  for  cases  in  which  you  do  n't  want  any  fragmentation  ,  simply  like  :

code statement(s):
setTextFragmenter(new NullFragmenter())

****************************** #77 ******************************
StackOverflow URL: https://stackoverflow.com/questions/16967100

comment sentences(s):
one  term  ,  which  matches  none  of  those  <em>  name  website  </em>

code statement(s):
new Term("textfield","name")
new Term("textfield","website")

****************************** #78 ******************************
StackOverflow URL: https://stackoverflow.com/questions/16967100

comment sentences(s):
The  correct  way  to  use  a  PhraseQuery  ,  is  to  add  each  term  to  the  PhraseQuery  separately  .

code statement(s):
phrase.add(new Term("textfield","name"))
phrase.add(new Term("textfield","website"))

****************************** #79 ******************************
StackOverflow URL: https://stackoverflow.com/questions/22192643

comment sentences(s):
You  can  iterate  over  document  fields  like  this  :  But  it  will  work  only  for  fields  which  are  stored  in  index ( those  which  was  added  with  Field.Store.YES  flag ) .

code statement(s):
for(IndexableField field : doc.getFields())

****************************** #80 ******************************
StackOverflow URL: https://stackoverflow.com/questions/21852068

comment sentences(s):
If  you  want  to  find  documents  which  contains  keyword1  in  field1  and  keyword2  in  field2  then  boolean  query  may  help  :

code statement(s):
query.add(new TermQuery(new Term("field2","keyword2")),BooleanClause.Occur.MUST)

****************************** #81 ******************************
StackOverflow URL: https://stackoverflow.com/questions/21349646

comment sentences(s):
You  need  to  set  the  parameter  for  the  fields  with  the  words  also  to  Field.Index.TOKENIZED  because  searching  is  only  possible  when  you  tokenize  .

code statement(s):
new Field("FIELD1","string1",Field.Store.YES,Field.Index.TOKENIZED)
new Field("FIELD2","string2",Field.Store.YES,Field.Index.TOKENIZED)

****************************** #82 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19688145

comment sentences(s):
The  easier  way  to  get  the  total  number  of  occurances  of  a  term  in  the  index  ,  as  per  the  linked-to  answer  ,  would  be  :

code statement(s):
numOccurances=indexReader.totalTermFreq(term)

****************************** #83 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19453153

comment sentences(s):
I  am  having  a  need  to  update  value  of  a  field  to  a  new  value  .

code statement(s):
updateDocument.addField("stuffedAnimals",new HashMap(){
{
    put("add","pink fluffy flamingo");
  }
}
)

****************************** #84 ******************************
StackOverflow URL: https://stackoverflow.com/questions/26278398

comment sentences(s):
You  can  use  regexp  filter  like  this  .

code statement(s):
FilterBuilder qFilter=FilterBuilders.regexpFilter("_all",(".*" + q + ".*").replace(" ",".*"));


****************************** #85 ******************************
StackOverflow URL: https://stackoverflow.com/questions/26101010

comment sentences(s):
Alternatively  you  can  use  the  native  Lucene  query  API  to  build  your  query  .

code statement(s):
Query luceneQuery=mythQB.keyword().onField("history").matching("storm").createQuery();


****************************** #86 ******************************
StackOverflow URL: https://stackoverflow.com/questions/26080078

comment sentences(s):
I  could  get  rid  of  this  by  recreating  my  working  directory  after  all  indexing  operations  :  create  a  new  directory  just  for  this  indexing  operations  named  ``  path_dir  ''  for  example  .

code statement(s):
FSDirectory.open(new File(path_dir))

****************************** #87 ******************************
StackOverflow URL: https://stackoverflow.com/questions/25715591

comment sentences(s):
For  instance  ,  if  you  set  the  indexing  analyzer  to  be  StandardAnalzyer  ,  then  you  need  also  to  apply  it  to  your  query  like  this  :

code statement(s):
new QueryParser(Version.LUCENE_CURRENT,"firstName",new StandardAnalyzer(Version.LUCENE_CURRENT))

****************************** #88 ******************************
StackOverflow URL: https://stackoverflow.com/questions/25689228

comment sentences(s):
You  just  need  to  set  the  IndexSearcher  's  similarity  :

code statement(s):
searcher.setSimilarity(new BM25Similarity(1.2,0.75))

****************************** #89 ******************************
StackOverflow URL: https://stackoverflow.com/questions/25611108

comment sentences(s):
The  third  argument  to  the  IndexWriter  constructor  specifies  whether  a  new  index  should  be  created  .

code statement(s):
new IndexWriter(directory,analyzer,false,IndexWriter.MaxFieldLength.LIMITED)

****************************** #90 ******************************
StackOverflow URL: https://stackoverflow.com/questions/25611108

comment sentences(s):
Set  it  to  false  in  order  to  open  the  old  index  ,  rather  than  overwriting  it  .

code statement(s):
new IndexWriter(directory,analyzer,false,IndexWriter.MaxFieldLength.LIMITED)

****************************** #91 ******************************
StackOverflow URL: https://stackoverflow.com/questions/25309382

comment sentences(s):
Yes  ,  there  is  a  way  core  itself  can  reload  itself  .

code statement(s):
core.getCoreDescriptor().getCoreContainer().reload(core.getName())

****************************** #92 ******************************
StackOverflow URL: https://stackoverflow.com/questions/25309382

comment sentences(s):
core  actually  has  the  coreContainer  object  which  created  it  .

code statement(s):
core.getCoreDescriptor().getCoreContainer().reload(core.getName())

****************************** #93 ******************************
StackOverflow URL: https://stackoverflow.com/questions/25309382

comment sentences(s):
And  through  coreContainer  you  can  reload  the  same  .

code statement(s):
core.getCoreDescriptor().getCoreContainer().reload(core.getName())

****************************** #94 ******************************
StackOverflow URL: https://stackoverflow.com/questions/25191327

comment sentences(s):
Actually  it  's  simple  i  have  to  add  a  property  to  the  node

code statement(s):
nodeService.setProperty(res.getNodeRef(),ContentModel.PROP_IS_INDEXED,"false")

****************************** #95 ******************************
StackOverflow URL: https://stackoverflow.com/questions/25178328

comment sentences(s):
For  <em>  StringField  </em>  ,  you  can  use  <strong>  TermQuery  </strong>  instead  of  <em>  QueryParser  </em>

code statement(s):
Query query=new TermQuery(new Term("countryCode",countryCode));


****************************** #96 ******************************
StackOverflow URL: https://stackoverflow.com/questions/25154279

comment sentences(s):
You  should  try  get  directory  method  .

code statement(s):
FSDirectory objDirectory=FSDirectory.GetDirectory(pstrDatabase_path);


****************************** #97 ******************************
StackOverflow URL: https://stackoverflow.com/questions/23863244

comment sentences(s):
Try  using  Regex  like  this  below  :  I  've  used  this  pattern  ''  -LSB-  ^  A-Za-z0-9  -RSB-  ''  to  replace  all  non-alphanumeric  string  with  a  blank  .

code statement(s):
sNewString=Regex.Replace(strInput,"[^A-Za-z0-9]",strToReplace)

****************************** #98 ******************************
StackOverflow URL: https://stackoverflow.com/questions/23388770

comment sentences(s):
Call  them  reader1  and  reader2  .

code statement(s):
new MultiReader(reader1,reader2)

****************************** #99 ******************************
StackOverflow URL: https://stackoverflow.com/questions/28848288

comment sentences(s):
I  think  what  you  need  is  a  <strong>  PhraseQuery  </strong>  ,  it  is  a  Lucene  <strong>  Query  </strong>  type  that  will  take  into  account  the  precise  position  of  your  tokens  and  allow  you  to  define  a  <strong>  slop  </strong>  or  permutation  tolerance  regarding  those  tokens  .

code statement(s):
PhraseQuery query=analyzedBuilder.createPhraseQuery("fieldToSearchOn",textQuery);


****************************** #100 ******************************
StackOverflow URL: https://stackoverflow.com/questions/28610313

comment sentences(s):
It  could  be  solved  easily  with  help  of  basic  rewrite  methods  in  MultiTermQuery  As  javadoc  said  :  <blockquote>  The  recommended  rewrite  method  is  CONSTANT_SCORE_AUTO_REWRITE_DEFAULT  :  it  does  n't  spend  CPU  computing  unhelpful  scores  ,  and  it  tries  to  pick  the  most  performant  rewrite  method  given  the  query  .

code statement(s):
query.setRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE)

****************************** #101 ******************************
StackOverflow URL: https://stackoverflow.com/questions/28610313

comment sentences(s):
basic  rewrite  methods

code statement(s):
setRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE)

****************************** #102 ******************************
StackOverflow URL: https://stackoverflow.com/questions/28610313

comment sentences(s):
<blockquote>  The  recommended  rewrite  method  is  CONSTANT_SCORE_AUTO_REWRITE_DEFAULT

code statement(s):
setRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE)

****************************** #103 ******************************
StackOverflow URL: https://stackoverflow.com/questions/28113558

comment sentences(s):
To  turn  norms  on  ,  you  'll  need  to  define  your  own  field  types  :

code statement(s):
Field nameField=new Field("name",name,myStringType);


****************************** #104 ******************************
StackOverflow URL: https://stackoverflow.com/questions/27675851

comment sentences(s):
You  forget  to  add  setTokenized ( true ) .

code statement(s):
setTokenized(true)

****************************** #105 ******************************
StackOverflow URL: https://stackoverflow.com/questions/27175315

comment sentences(s):
When  you  're  asking  for  a  particular  document  to  be  explained  ,  you  're  doing  so  with  your  search  query  and  a  document  ID  .

code statement(s):
search(query,filter,10)

****************************** #106 ******************************
StackOverflow URL: https://stackoverflow.com/questions/27138074

comment sentences(s):
But  you  could  execute  a  command  to  create  the  lucene  index  like  this  :

code statement(s):
graph.getRawGraph().command(new OCommandSQL("create index V.name on V (name) FULLTEXT ENGINE LUCENE")).execute()

****************************** #107 ******************************
StackOverflow URL: https://stackoverflow.com/questions/27138074

comment sentences(s):
a  command  to  create  the  lucene  index  like  this

code statement(s):
command(new OCommandSQL("create index V.name on V (name) FULLTEXT ENGINE LUCENE"))

****************************** #108 ******************************
StackOverflow URL: https://stackoverflow.com/questions/27110756

comment sentences(s):
For  others  who  might  be  looking  ,  with  lucene  4.0  ,  initialize  parser  with  empty  char  set

code statement(s):
WordnetSynonymParser parse=new WordnetSynonymParser(true,true,new StandardAnalyzer(CharArraySet.EMPTY_SET));


****************************** #109 ******************************
StackOverflow URL: https://stackoverflow.com/questions/35550479

comment sentences(s):
I  think  you  need  to  use  the  GroupedOr  method  of  the  search  criteria  to  generate  your  query  .

code statement(s):
query=provider.CreateSearchCriteria(BooleanOperation.And).GroupedOr(siteSearchFields,searchTerms).Compile()

****************************** #110 ******************************
StackOverflow URL: https://stackoverflow.com/questions/35550479

comment sentences(s):
The  GroupedOr  method  expects  two  lists  ,  one  of  field  names  ,  and  one  of  search  keywords  .

code statement(s):
provider.CreateSearchCriteria(BooleanOperation.And).GroupedOr(siteSearchFields,searchTerms)

****************************** #111 ******************************
StackOverflow URL: https://stackoverflow.com/questions/35549352

comment sentences(s):
You  really  want  to  create  two  queries  ,  one  against  the  first  name  and  one  against  the  last  name  and  then  combine  them  via  the  <em>  SHOULD  </em>  operator  .

code statement(s):
Query combinedQuery=querybuilder.bool().should(firstNameQuery).should(lastNameQuery).createQuery();


****************************** #112 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34976120

comment sentences(s):
So  if  i  use  the  following  code  :  where  page  is  1  and  itemsPerPage  is  5  ,  but  my  filtered  results  returns  only  one  value ( or  less  then  itemsPerPage ) GetResults() returns  no  results  !

code statement(s):
results=query.Page(page,itemsPerPage).GetResults()

****************************** #113 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34976120

comment sentences(s):
page  is  1  and  itemsPerPage

code statement(s):
Page(page,itemsPerPage)

****************************** #114 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34976120

comment sentences(s):
only  one  value ( or  less  then  itemsPerPage ) GetResults ( )

code statement(s):
query.Page(page,itemsPerPage).GetResults()

****************************** #115 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34682927

comment sentences(s):
The  result  for  this  is  using  LongField  example  to  solve  the  problem  :

code statement(s):
new LongField(FILE_MODIFIED,modified,Field.Store.YES)

****************************** #116 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34158952

comment sentences(s):
You  should  use  a  custom  Analyzer  with  LengthTokeFilter  .

code statement(s):
Analyzer ana=CustomAnalyzer.builder().withTokenizer("standard").addTokenFilter("standard").addTokenFilter("lowercase").addTokenFilter("length","min","4","max","50").addTokenFilter("stop","ignoreCase","false","words","stopwords.txt","format","wordset").build();


****************************** #117 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31961241

comment sentences(s):
whitespace  tokenization

code statement(s):
Tokenizer whitespaceTokenizer=new WhitespaceTokenizer();


****************************** #118 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31961241

comment sentences(s):
remove  stop  words  with  <strong>  StopFilter  </strong>

code statement(s):
new StopFilter(whitespaceTokenizer,StopAnalyzer.ENGLISH_STOP_WORDS_SET)

****************************** #119 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31756568

comment sentences(s):
Another  easy  approach  to  search  across  all  fields  using  ''  MultifieldQueryParser  ''  is  use  <strong>  IndexReader.FieldOption.ALL  </strong>  in  your  query  .

code statement(s):
new MultiFieldQueryParser(Version.LUCENE_29,indexReader__1.GetFieldNames(IndexReader.FieldOption.ALL).ToArray(),analyzer)

****************************** #120 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31598837

comment sentences(s):
So  it  would  be  something  like  this  :  There  ,  your  mlt  query  would  be  boosted  to  50  times  it  's  normal  score  <em>  relative  to  the  other  subquery  </em>  .

code statement(s):
QueryBuilders.boolQuery.should(mltQuery.boost(50)).should(someOtherQueryBuilder)

****************************** #121 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31598837

comment sentences(s):
boosted  to  50  times

code statement(s):
boost(50)

****************************** #122 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31579998

comment sentences(s):
I  just  use  the  Stringfield  for  the  problem  .

code statement(s):
StringField field=new StringField(key,value,Field.Store.YES);


****************************** #123 ******************************
StackOverflow URL: https://stackoverflow.com/questions/35732401

comment sentences(s):
You  need  to  store  the  field  in  order  to  retrieve  it  .

code statement(s):
new TextField("mytext","some text",Field.Store.YES)

****************************** #124 ******************************
StackOverflow URL: https://stackoverflow.com/questions/35550479

comment sentences(s):
I  think  you  need  to  use  the  GroupedOr  method  of  the  search  criteria  to  generate  your  query  .

code statement(s):
query=provider.CreateSearchCriteria(BooleanOperation.And).GroupedOr(siteSearchFields,searchTerms).Compile()

****************************** #125 ******************************
StackOverflow URL: https://stackoverflow.com/questions/35550479

comment sentences(s):
the  GroupedOr  method  of  the  search  criteria

code statement(s):
provider.CreateSearchCriteria(BooleanOperation.And).GroupedOr(siteSearchFields,searchTerms)

****************************** #126 ******************************
StackOverflow URL: https://stackoverflow.com/questions/35550479

comment sentences(s):
The  GroupedOr  method  expects  two  lists  ,  one  of  field  names  ,  and  one  of  search  keywords  .

code statement(s):
provider.CreateSearchCriteria(BooleanOperation.And).GroupedOr(siteSearchFields,searchTerms)

****************************** #127 ******************************
StackOverflow URL: https://stackoverflow.com/questions/35549352

comment sentences(s):
You  really  want  to  create  two  queries  ,  one  against  the  first  name  and  one  against  the  last  name  and  then  combine  them  via  the  <em>  SHOULD  </em>  operator  .

code statement(s):
Query combinedQuery=querybuilder.bool().should(firstNameQuery).should(lastNameQuery).createQuery();


****************************** #128 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34976120

comment sentences(s):
page  is  1  and  itemsPerPage

code statement(s):
Page(page,itemsPerPage)

****************************** #129 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34976120

comment sentences(s):
only  one  value ( or  less  then  itemsPerPage ) GetResults ( )

code statement(s):
query.Page(page,itemsPerPage).GetResults()

****************************** #130 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34682927

comment sentences(s):
The  result  for  this  is  using  LongField  example  to  solve  the  problem  :

code statement(s):
new LongField(FILE_MODIFIED,modified,Field.Store.YES)

****************************** #131 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34158952

comment sentences(s):
You  should  use  a  custom  Analyzer  with  LengthTokeFilter  .

code statement(s):
Analyzer ana=CustomAnalyzer.builder().withTokenizer("standard").addTokenFilter("standard").addTokenFilter("lowercase").addTokenFilter("length","min","4","max","50").addTokenFilter("stop","ignoreCase","false","words","stopwords.txt","format","wordset").build();


****************************** #132 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34158952

comment sentences(s):
But  it  is  better  to  use  a  stopword ( words  what  occur  in  almost  all  documents  ,  like  articles  for  English  language ) list  .

code statement(s):
addTokenFilter("stop","ignoreCase","false","words","stopwords.txt","format","wordset")

****************************** #133 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31961241

comment sentences(s):
whitespace  tokenization

code statement(s):
Tokenizer whitespaceTokenizer=new WhitespaceTokenizer();


****************************** #134 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31961241

comment sentences(s):
remove  stop  words  with  <strong>  StopFilter  </strong>

code statement(s):
new StopFilter(whitespaceTokenizer,StopAnalyzer.ENGLISH_STOP_WORDS_SET)

****************************** #135 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31598837

comment sentences(s):
So  it  would  be  something  like  this  :  There  ,  your  mlt  query  would  be  boosted  to  50  times  it  's  normal  score  <em>  relative  to  the  other  subquery  </em>  .

code statement(s):
QueryBuilders.boolQuery.should(mltQuery.boost(50)).should(someOtherQueryBuilder)

****************************** #136 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31598837

comment sentences(s):
boosted  to  50  times

code statement(s):
boost(50)

****************************** #137 ******************************
StackOverflow URL: https://stackoverflow.com/questions/1977852

comment sentences(s):
The  first ( including  all  terms ) is  not  ,  but  you  can  force  this  behavior  by  setting  the  default  operator  :  I  know  that  items  2  ,  4  ,  and  6  are  possible  ,  and  IIRC  ,  they  happen  by  default  .

code statement(s):
setDefaultOperator(QueryParser.AND_OPERATOR)

****************************** #138 ******************************
StackOverflow URL: https://stackoverflow.com/questions/1846405

comment sentences(s):
You  add  four  fields  to  each  document  ,  all  of  them  are  stored  but  none  of  them  is  indexed ( =  >  Lucene.Net.Documents.Field.Index.NO ) .

code statement(s):
Add(new PrefixQuery(new Term("B","lala")),BooleanClause.Occur.MUST)
Add(new PrefixQuery(new Term("C","dodo")),BooleanClause.Occur.MUST)

****************************** #139 ******************************
StackOverflow URL: https://stackoverflow.com/questions/1827116

comment sentences(s):
potetescaricare  a  questo  link

code statement(s):
"Pubblichiamo la presentazione di IBM riguardante DB2 per i vari sistemi operativi" + "Linux, UNIX e Windows.\r\n\r\nQuesto documento sta sulla piattaforma KM e lo potete" + "scaricare a questo &lt;a href=\'https://sfkm.griffon.local/sites/BSF%20KM/BSF/CC%20T/Specifiche/Eventi2008/IBM%20DB2%20for%20Linux,%20UNIX%20e%20Windows.pdf\' target=blank&gt;link&lt;/a&gt;."

****************************** #140 ******************************
StackOverflow URL: https://stackoverflow.com/questions/1433524

comment sentences(s):
Looking  at  your  code  I  think  you  need  to  add  each  query ( one  for  the  SearchKey  and  one  for  the  Type ) to  the  BooleanQuery  like  below  .

code statement(s):
filterQuery.Add(query1,BooleanClause.Occur.MUST)
filterQuery.Add(query1,BooleanClause.Occur.MUST)

****************************** #141 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3948411

comment sentences(s):
You  need  to  add  the  tier  prefix  to  the  query  builder  :

code statement(s):
DistanceQueryBuilder dq=new DistanceQueryBuilder(coord.getLat(),coord.getLon(),miles,Spatial.LAT_FIELD,Spatial.LON_FIELD,Spatial.TIER_PREFIX_FIELD,false);


****************************** #142 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3348457

comment sentences(s):
-RSB-  -  attribute  to  the  IsDeleted  property  ,  and  added  this  clause  to  any  query  inbound  :  I  knew  it  was  something  simple  :

code statement(s):
"(" + userQuery + ") AND IsDeleted:False"

****************************** #143 ******************************
StackOverflow URL: https://stackoverflow.com/questions/2702284

comment sentences(s):
I  think  you  should  use  the  QueryParser  and  let  it  build  the  appropriate  Query  object  instead  of  using  something  specific  like  the  PrefixQuery  .

code statement(s):
QueryParser parser=new QueryParser(Version.LUCENE_CURRENT,"nombreAnalizado",new StandardAnalyzer(Version.LUCENE_CURRENT));


****************************** #144 ******************************
StackOverflow URL: https://stackoverflow.com/questions/2702284

comment sentences(s):
In  Java  :  Make  sure  you  are  using  the  same  analyzer  that  you  used  for  indexing  .

code statement(s):
new QueryParser(Version.LUCENE_CURRENT,"nombreAnalizado",new StandardAnalyzer(Version.LUCENE_CURRENT))

****************************** #145 ******************************
StackOverflow URL: https://stackoverflow.com/questions/2296132

comment sentences(s):
The  thing  I ( and  anyone  who  was  searching  for  solution  of  the  same  problem ) needed  is  setting  up  Criteria  for  the  FullTextQuery  .

code statement(s):
setCriteriaQuery(criteria)

****************************** #146 ******************************
StackOverflow URL: https://stackoverflow.com/questions/2075366

comment sentences(s):
This  should  work  with  both  the  KeywordAnalyzer  and  the  StandardAnalyzer  .

code statement(s):
luceneAnalyzer=new KeywordAnalyzer()

****************************** #147 ******************************
StackOverflow URL: https://stackoverflow.com/questions/5886435

comment sentences(s):
I  think  the  searcher  bean  forces  everything  to  lowercase  ...  so  make  the  state  is  in  lower  case  when  adding  to  the  index  :  and  when  you  query  :  `  state  :  irn_ca  '  instead  of  `  state  :  irn_CA  '  .

code statement(s):
new Field("state","irn_" + state.toLowerCase(),Field.Store.NO,Field.Index.UN_TOKENIZED)

****************************** #148 ******************************
StackOverflow URL: https://stackoverflow.com/questions/5513253

comment sentences(s):
Lucene.Net.Search.Sort  constructor  has  an  overload  to  reverse  sorting  order  :  From  :  http://www.google.com/codesearch/p?hl=en#sbnThrht2Bk/trunk/Lucene.Net/Search/Sort.cs&amp;q=Lucene.Net.Search.Sort&amp;sa=N&amp;cd=1&amp;ct=rc

code statement(s):
sort=new Lucene.Net.Search.Sort(new Lucene.Net.Search.SortField("date",Lucene.Net.Search.SortField.LONG),true)

****************************** #149 ******************************
StackOverflow URL: https://stackoverflow.com/questions/5199449

comment sentences(s):
You  need  it  to  be  stored  if  you  want  to  use  that  highlighter  .

code statement(s):
new Field("filename",f.getName(),Field.Store.YES,Field.Index.ANALYZED)

****************************** #150 ******************************
StackOverflow URL: https://stackoverflow.com/questions/5145942

comment sentences(s):
Where  `  date  '  is  a  date  field  on  your  document  that  you  want  to  boost  and  compassBuilderQuery  is  a  query  you  have  generated  with  the  compass  query  builder  .

code statement(s):
final SimpleDateFormat sdf=new SimpleDateFormat("yyyyMMddHHmmss");


****************************** #151 ******************************
StackOverflow URL: https://stackoverflow.com/questions/8071184

comment sentences(s):
Something  like  this  should  work  :  What  fouled  me  up  was  I  originally  tried  connecting  the  client  to  9200  ,  not  9300  .

code statement(s):
client.addTransportAddress(new InetSocketTransportAddress("localhost",9300))

****************************** #152 ******************************
StackOverflow URL: https://stackoverflow.com/questions/7811870

comment sentences(s):
<br>  Lucene  exposes  classes  as  IndexWriter  and  IndexSearcher  ,  which  would  help  you  interact  with  index  .

code statement(s):
IndexSearcher searcher=new IndexSearcher(index,true);


****************************** #153 ******************************
StackOverflow URL: https://stackoverflow.com/questions/7804979

comment sentences(s):
``  T  ''  is  a  stop  word  by  default  in  standard  analyzer  .

code statement(s):
StandardAnalyzer standardAnalyzer=new StandardAnalyzer(new string[]{"an","a"});


****************************** #154 ******************************
StackOverflow URL: https://stackoverflow.com/questions/7191583

comment sentences(s):
You  need  to  use  a  BooleanQuery  with  the  SHOULD  clause  .

code statement(s):
query.Add(new TermQuery(new Term("ID","a"),Occur.SHOULD))
query.Add(new TermQuery(new Term("ID","b"),Occur.SHOULD))
query.Add(new TermQuery(new Term("ID","c"),Occur.SHOULD))

****************************** #155 ******************************
StackOverflow URL: https://stackoverflow.com/questions/7052681

comment sentences(s):
If  you  have  your  field  indexed  as  a  ``  string  ''  type ( instead  of  ``  text  ''  type ) ,  your  regex  would  have  to  match  the  <em>  whole  </em>  field  value  .

code statement(s):
regexQueryNrHits("^.*bug [0-9]+.*$",null)

****************************** #156 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6782573

comment sentences(s):
connect() did  n't  even  actually  open  a  connection  to  my  test  server  .

code statement(s):
connection.connect()

****************************** #157 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6782573

comment sentences(s):
It  was  n't  until  I  called  getContent() that  the  client  connected  and  issued  an  HTTP  request  .

code statement(s):
connection.getContent()

****************************** #158 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6729358

comment sentences(s):
You  are  using  a  standard  tokenizer  which  at  least  tokenizes  on  a  whitespace  level  so  you  will  always  have  ``  hello  world  ''  be  split  to  ``  hello  ''  and  ``  world  ''  .

code statement(s):
TokenStream stream=new StandardTokenizer(Version.LUCENE_32,reader);


****************************** #159 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6475687

comment sentences(s):
I  would  strongly  recommend  the  use  of  BooleanQuery  with  stnadard  QueryParser  :  This  way  you  can  perform  search  on  exactly  the  fields  you  want  and  adjust  it  to  produce  fine  tuned  results  .

code statement(s):
booleanQuery.add(field1Query,BooleanClause.Occur.SHOULD)
booleanQuery.add(field1Query,BooleanClause.Occur.SHOULD)

****************************** #160 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6475687

comment sentences(s):
perform  search  on  exactly  the  fields  you  want

code statement(s):
field1Query=new FuzzyQuery(new Term("field1",searchTerm),0.3f,1,10)
field2Query=new FuzzyQuery(new Term("field2",searchTerm),0.3f,1,10)

****************************** #161 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6028374

comment sentences(s):
Also  is  the  max  version  something  you  can  determine  beforehand  and  cache  ?

code statement(s):
fullTextQuery.enableFullTextFilter("version").setParameter("max",1001)

****************************** #162 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9986841

comment sentences(s):
an  end  date

code statement(s):
new Term("EndDate",searchableDate)

****************************** #163 ******************************
StackOverflow URL: https://stackoverflow.com/questions/8297471

comment sentences(s):
Assuming  all  your  docs  have  a  pageTypeId  you  can  try  using  a  MatchAllDocsQuery  and  then  a  MUST_NOT  to  remove  all  the  docs  you  want  to  skip  .

code statement(s):
Add(new MatchAllDocsQuery(),BooleanClause.Occur.MUST)

****************************** #164 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13415105

comment sentences(s):
config  is  an  IndexWriterConfig  object

code statement(s):
indexDictionary(new PlainTextDictionary(new File("fulldictionary00.txt")),config,false)

****************************** #165 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13377258

comment sentences(s):
For  your  case  of  plain  text  dictionary  file  ,  you  should  use  <strong>  PlainTextDictionary  </strong>  <blockquote>  Dictionary  represented  by  a  text  file  .

code statement(s):
indexDictionary(new LuceneDictionary(my_luceneReader,my_fieldname))

****************************** #166 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13218498

comment sentences(s):
SnowballAnalyzer  is  deprecated  ,  you  can  use  Lucene  Porter  Stemmer  instead  :  Hope  this  help  !

code statement(s):
PorterStemmer stem=new PorterStemmer();


****************************** #167 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12818752

comment sentences(s):
You  should  use  a  range  query  using  <em>  from  </em>  and  <em>  to  </em>  .

code statement(s):
query=monthQb.range().onField("startTS").ignoreFieldBridge().from(DateTools.dateToString(from,DateTools.Resolution.MILLISECOND)).to(DateTools.dateToString(to,DateTools.Resolution.MILLISECOND)).excludeLimit().createQuery()

****************************** #168 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12818752

comment sentences(s):
The  ignoreFieldBridge  is  needed  since  you  create  the  string  based  search  string  yourself  using  <em>  DateTools  </em>  .

code statement(s):
monthQb.range().onField("startTS").ignoreFieldBridge().from(DateTools.dateToString(from,DateTools.Resolution.MILLISECOND)).to(DateTools.dateToString(to,DateTools.Resolution.MILLISECOND)).excludeLimit().createQuery()

****************************** #169 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12789416

comment sentences(s):
You  can  set  the  rewrite  method  yourself

code statement(s):
setRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE)

****************************** #170 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12717591

comment sentences(s):
use  the  projection  API  :  Using  projections  you  get  to  read  any  field  as  long  as  it  's  STORED

code statement(s):
setProjection("myField1","myField2")

****************************** #171 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12717591

comment sentences(s):
An  example  FieldBridge  implementation  writing  multiple  fields  is  the  DateSplitBridge  in  the  documentation  .

code statement(s):
setProjection("myField1","myField2")

****************************** #172 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12502131

comment sentences(s):
If  you  know  you  need  the  last  childitem  of  /  sitecore/content/data  /  MyItem  ,  you  could  also  use  a  more  simple  approach  and  get  the  parentItem  and  then  retrieve  the  last  child  :  The  same  could  be  done  with  Descendants  instead  of  Children  .

code statement(s):
Item myItem=Sitecore.Context.Database.GetItem("/sitecore/content/data/MyItem");


****************************** #173 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12502131

comment sentences(s):
of  /  sitecore/content/data  /  MyItem

code statement(s):
myItem=Sitecore.Context.Database.GetItem("/sitecore/content/data/MyItem")

****************************** #174 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12003138

comment sentences(s):
Try  using  MultiFieldQueryParser

code statement(s):
new MultiFieldQueryParser(Version.LUCENE_36,fields,analyzer)

****************************** #175 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
Try  indexing  your  NumericField  with  a  precision  step  of  Int32.MaxValue  and  the  values  will  go  away  .

code statement(s):
NumericField number=new NumericField("number",Field.Store.YES,true);


****************************** #176 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
You  can  use  the  expert  constructor  NumericField ( String  ,  int  ,  Field.Store  ,  boolean ) if  you  'd  like  to  change  the  value  .

code statement(s):
number.SetIntValue(1)
number.SetIntValue(2)
number.SetIntValue(13)
number.SetIntValue(2000)
number.SetIntValue(9999)

****************************** #177 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
Using  NumericFields  for  sorting  is  ideal  ,  because  building  the  field  cache  is  much  faster  than  with  text-only  numbers  .

code statement(s):
NumericField number=new NumericField("number",Field.Store.YES,true);


****************************** #178 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11269749

comment sentences(s):
But  the  first  query  will  also  find  this  abc  1,2,3,4,5,6,7,8  ,  def  ,1,2,3,4,5,6,8  ghi  ,  a  ,  b  ,  c  ,  d  ,  e  ,  f  ,  g  ,  h  ,  i  ,  abc  ,1,2,3  ,  def  ,1,2,3,4,5,6,7,8,9,10  ,  def  ,1,2,3,4,5  ,  ghi  I  think  you  do  n't  want  the  second  document  in  your  search  results  .

code statement(s):
{new SpanTermQuery(new Term(FIELD,"abc")),new SpanTermQuery(new Term(FIELD,"def"))}

****************************** #179 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11269749

comment sentences(s):
it  seems  like  it  supports  span  queries  .

code statement(s):
SpanNearQuery spanNear=new SpanNearQuery(new SpanQuery[]{new SpanTermQuery(new Term(FIELD,"abc")),new SpanTermQuery(new Term(FIELD,"def"))},3,true);


****************************** #180 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11269749

comment sentences(s):
You  can  use  span  queries  for  proximity  searches  .

code statement(s):
SpanNearQuery spanNear=new SpanNearQuery(new SpanQuery[]{new SpanTermQuery(new Term(FIELD,"abc")),new SpanTermQuery(new Term(FIELD,"def"))},3,true);


****************************** #181 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11269749

comment sentences(s):
For  mor  info  check  Mark  Miller  's  article  about  span  queries  .

code statement(s):
SpanNearQuery spanNear=new SpanNearQuery(new SpanQuery[]{new SpanTermQuery(new Term(FIELD,"abc")),new SpanTermQuery(new Term(FIELD,"def"))},3,true);


****************************** #182 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11239085

comment sentences(s):
I  just  tested  with  my  worker  Role  with  exact  code ( just  using  Standard  Analyzer  and  the  worker  role  DLL  was  created  without  any  problem  .

code statement(s):
Analyzer analyzer=new StandardAnalyzer(Lucene.Net.Util.Version.LUCENE_29);


****************************** #183 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11148205

comment sentences(s):
Lucene  3  :  <ul>  C#  :  C#  Lucene  get  all  the  index    Java  :    Java ( all  terms  for  a  specific  field ) :  How  can  I  get  the  list  of  unique  terms  from  a  specific  field  in  Lucene  ?

code statement(s):
term=termEnum.term()

****************************** #184 ******************************
StackOverflow URL: https://stackoverflow.com/questions/16303616

comment sentences(s):
The  solution  ,  I  think  ,  would  be  to  save  the  boost  as  a  field  stored  in  the  index  ,  and  retrieve  that  ,  and  use  it  to  modify  and  set  the  boost  .

code statement(s):
Field boostField=oldDoc.getField("saved_boost");


****************************** #185 ******************************
StackOverflow URL: https://stackoverflow.com/questions/15966127

comment sentences(s):
I  think  you  should  try  to  also  specify  your  core  whenever  you  are  referring  to  SolrServer  object  ,  i.e.  ,  write  where  collection1  is  the  name  of  the  core  that  you  want  to  use  .

code statement(s):
SolrServer solr=new HttpSolrServer("http://localhost:8080/solr/collection1");


****************************** #186 ******************************
StackOverflow URL: https://stackoverflow.com/questions/15293747

comment sentences(s):
for  example  :  I  think  that  Lucene  requires  you  to  tell  it  on  which  field ( s )( title  ,  content  ... ) you  want  to  run  your  query  .

code statement(s):
Lucene.Net.Search.Query qry=parser.Parse("content: morning");


****************************** #187 ******************************
StackOverflow URL: https://stackoverflow.com/questions/15251033

comment sentences(s):
You  can  use  the  index  reader  :  Omri

code statement(s):
IndexReader reader=IndexReader.open(FSDirectory.open(indexDirectory));


****************************** #188 ******************************
StackOverflow URL: https://stackoverflow.com/questions/15207701

comment sentences(s):
prepare  a  query  for  each  field ( using  the  same  search  keywords  )

code statement(s):
Query query=new WildcardQuery(new Term(field,"*alue1"));


****************************** #189 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14782177

comment sentences(s):
I  do  n't  really  know  all  that  much  about  the  Surround  query  parser

code statement(s):
query=org.apache.lucene.queryparser.surround.parser.QueryParser.parse(queryString)

****************************** #190 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14683447

comment sentences(s):
Actually  you  dont  just  get  the  first  level  ,  lucene  returns  all  levels

code statement(s):
"  " + secondlvl.getLabel().getComponent(1) + " ("+ secondlvl.getValue()+ ")"

****************************** #191 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13707912

comment sentences(s):
But  you  want  to  search  with  a  longer  query  than  than  the  field  your  searching  ,  which  is  sort  of  the  reverse  of  the  typical  use  case  .

code statement(s):
Query query=parser.parse(query,defaultField);


****************************** #192 ******************************
StackOverflow URL: https://stackoverflow.com/questions/18133916

comment sentences(s):
If  we  talk  about  Lucene  ,  you  could  add  to  index  documents  ,  that  contains  two  fields  -  user  name  and  email  .

code statement(s):
add(new Field("userName",userName),Field.Store.YES,Field.Index.ANALYZED)

****************************** #193 ******************************
StackOverflow URL: https://stackoverflow.com/questions/22837160

comment sentences(s):
The  core  collection1  should  also  be  created  before  to  creating  the  EmbeddedSolrServer  instance  ,  try  something  like  this ( not  tested  with  your  code ) :

code statement(s):
SolrCore core=container.create(descr);


****************************** #194 ******************************
StackOverflow URL: https://stackoverflow.com/questions/22192643

comment sentences(s):
Also  if  you  have  several  values  for  the  field  in  the  document  this  code  has  to  be  modified  .

code statement(s):
put(field.name(),field.stringValue())

****************************** #195 ******************************
StackOverflow URL: https://stackoverflow.com/questions/21852068

comment sentences(s):
documents  which  contains  keyword1  in  field1  and  keyword2  in  field2  then

code statement(s):
add(new TermQuery(new Term("field2","keyword2")),BooleanClause.Occur.MUST)

****************************** #196 ******************************
StackOverflow URL: https://stackoverflow.com/questions/21852068

comment sentences(s):
field1  and  keyword2  in  field2

code statement(s):
new Term("field2","keyword2")

****************************** #197 ******************************
StackOverflow URL: https://stackoverflow.com/questions/20078179

comment sentences(s):
Yes  ,  use  HighFreqTerms  ,  like  :  Luke  also  prominently  displays  the  most  common  terms  .

code statement(s):
TermStats[] stats=HighFreqTerms.gethighFreqTerms(reader,10,"myContentField",new HighFreqTerms.DocFreqComparator());


****************************** #198 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19660239

comment sentences(s):
Also  you  need  to  convert  that  to  an  int  to  as  it  also  contains  time  in  the  decimal  part  .

code statement(s):
NewIntRange("StartDate",0,Convert.ToInt32(upperDate.ToOADate()),true,true)
NewIntRange("EndDate",Convert.ToInt32(lowerDate.ToOADate()),0,true,true)

****************************** #199 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19453153

comment sentences(s):
Using  the  Java  SolrJ  API  it  's  something  like  this  :  Let  's  say  you  have  a  document  with  a  multi  value  field  called  ``  stuffedAnimals  ''  .

code statement(s):
updateDocument.addField("stuffedAnimals",new HashMap(){
{
    put("add","pink fluffy flamingo");
  }
}
)

****************************** #200 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19453153

comment sentences(s):
a  multi  value  field  called  ``  stuffedAnimals  ''

code statement(s):
addField("stuffedAnimals",new HashMap(){
{
    put("add","pink fluffy flamingo");
  }
}
)

****************************** #201 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19453153

comment sentences(s):
</em>  Well  ,  as  I  was  saying  above  :  when  you  update  a  field  ,  the  document  is  actually  re-written  entirely  ,  so  that  means  it  's  re-indexed  with  the  new  field  as  well  .

code statement(s):
updateDocument.addField("stuffedAnimals",new HashMap(){
{
    put("add","pink fluffy flamingo");
  }
}
)

****************************** #202 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19453153

comment sentences(s):
Well  ,  as  I  was  saying  above  :  when  you  update  a  field  ,  the  document  is  actually  re-written  entirely

code statement(s):
updateDocument.addField("id",2312312)
updateDocument.addField("stuffedAnimals",new HashMap(){
{
    put("add","pink fluffy flamingo");
  }
}
)

****************************** #203 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19453153

comment sentences(s):
a  partial  update  on  a  field

code statement(s):
updateDocument.addField("id",2312312)
updateDocument.addField("stuffedAnimals",new HashMap(){
{
    put("add","pink fluffy flamingo");
  }
}
)

****************************** #204 ******************************
StackOverflow URL: https://stackoverflow.com/questions/26360886

comment sentences(s):
Try  to  use  Examine  Searcher  as  described  in  docs  :  http://our.umbraco.org/documentation/Reference/Searching/Examine/  http://umbraco.com/follow-us/blog-archive/2011/9/16/examining-examine.aspx

code statement(s):
searcher=ExamineManager.Instance.SearchProviderCollection["WebsiteSearcher"]

****************************** #205 ******************************
StackOverflow URL: https://stackoverflow.com/questions/24237792

comment sentences(s):
field  name  :  acet  ,  queryString  parktaeha  <blockquote>  ========  start  search  !!

code statement(s):
new TextField("acet",target,Field.Store.YES)

****************************** #206 ******************************
StackOverflow URL: https://stackoverflow.com/questions/30926385

comment sentences(s):
Use  the  LowerCaseFilter  as  the  post  you  referenced  suggests  :  A  more  complete  example  is  in  this  post  .

code statement(s):
new LowerCaseFilter(Version.LUCENE_CURRENT,stream)

****************************** #207 ******************************
StackOverflow URL: https://stackoverflow.com/questions/30752399

comment sentences(s):
Do  not  store  the  body  and  headline  field  to  your  index  .

code statement(s):
new Field("headline",head,Field.Store.No,Field.Index.ANALYZED)
new Field("body",head,Field.Store.No,Field.Index.ANALYZED)

****************************** #208 ******************************
StackOverflow URL: https://stackoverflow.com/questions/28558493

comment sentences(s):
I  've  run  the  test  locally  and  found  out  ,  that  the  problem  is  in  <strong>  precisionStep  </strong>  -  you  did  n't  index  properly  for  precisionStep  =  4  .

code statement(s):
setNumericPrecisionStep(4)

****************************** #209 ******************************
StackOverflow URL: https://stackoverflow.com/questions/28433072

comment sentences(s):
because  idf ( t  ,  D ) =  log ( N  \ ( d  in  D  :  t  in  d )) N  :  total  number  of  documents  in  the  corpus  d  in  D  :  t  in  d  :  number  of  documents  where  the  term  t  appears

code statement(s):
terms=fields.terms(field)

****************************** #210 ******************************
StackOverflow URL: https://stackoverflow.com/questions/27847504

comment sentences(s):
You  do  n't  need  to  add  the  fields  to  the  doc  on  every  iteration  .

code statement(s):
doc.add(field1)
doc.add(field2)

****************************** #211 ******************************
StackOverflow URL: https://stackoverflow.com/questions/35550479

comment sentences(s):
the  GroupedOr  method  of  the  search  criteria

code statement(s):
provider.CreateSearchCriteria(BooleanOperation.And).GroupedOr(siteSearchFields,searchTerms)

****************************** #212 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34158952

comment sentences(s):
But  it  is  better  to  use  a  stopword ( words  what  occur  in  almost  all  documents  ,  like  articles  for  English  language ) list  .

code statement(s):
addTokenFilter("stop","ignoreCase","false","words","stopwords.txt","format","wordset")

****************************** #213 ******************************
StackOverflow URL: https://stackoverflow.com/questions/32352475

comment sentences(s):
need  a  token  from  the  user  and  check

code statement(s):
tokenToReturn=mgr.record(is)
tokenToReturn=mgr.record(is)

****************************** #214 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31992782

comment sentences(s):
At  index  time  ,  it  is  possible  to  add  the  urls  in  two  separate  fields  :  url1  searchable ( indexed ) ,  and  url2  ,  just  stored  .

code statement(s):
add(new StringField("url1",url1String,Store.NO))

****************************** #215 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31992782

comment sentences(s):
the  urls  in  two  separate  fields

code statement(s):
new StringField("url1",url1String,Store.NO)
new StoredField("url2",url2String)

****************************** #216 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31549482

comment sentences(s):
  When  searching  -  use  DuplicateFilter    </ol>

code statement(s):
df.setKeepMode(DuplicateFilter.KM_USE_LAST_OCCURRENCE)

****************************** #217 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31478192

comment sentences(s):
You  can  use  a  boolean  query  like  :  must

code statement(s):
Query luceneQuery=b.bool().must(b.keyword().onField("fieldName").matching("term1").createQuery()).must(b.keyword().onField("fieldName").matching("term2").createQuery()).should(b.keyword().onField("fieldName").matching("term3").createQuery()).except(b.keyword().onField("fieldName").matching("term4").createQuery()).createQuery();


****************************** #218 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34976120

comment sentences(s):
So  if  i  use  the  following  code  :  where  page  is  1  and  itemsPerPage  is  5  ,  but  my  filtered  results  returns  only  one  value ( or  less  then  itemsPerPage ) GetResults() returns  no  results  !

code statement(s):
results=query.Page(page,itemsPerPage).GetResults()

****************************** #219 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31992782

comment sentences(s):
the  urls  in  two  separate  fields  :  url1  searchable ( indexed ) ,  and  url2  ,  just  stored

code statement(s):
new StringField("url1",url1String,Store.NO)

****************************** #220 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31992782

comment sentences(s):
the  urls  in  two  separate  fields

code statement(s):
new StringField("url1",url1String,Store.NO)
new StoredField("url2",url2String)

****************************** #221 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31756568

comment sentences(s):
Another  easy  approach  to  search  across  all  fields  using  ''  MultifieldQueryParser  ''  is  use  <strong>  IndexReader.FieldOption.ALL  </strong>  in  your  query  .

code statement(s):
new MultiFieldQueryParser(Version.LUCENE_29,indexReader__1.GetFieldNames(IndexReader.FieldOption.ALL).ToArray(),analyzer)

****************************** #222 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31678500

comment sentences(s):
You  can  achieve  this  by  using  multiple  boolean  queries  .

code statement(s):
BooleanQuery finalQuery=new BooleanQuery();


****************************** #223 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31579998

comment sentences(s):
I  just  use  the  Stringfield  for  the  problem  .

code statement(s):
StringField field=new StringField(key,value,Field.Store.YES);


****************************** #224 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31549482

comment sentences(s):
  When  searching  -  use  DuplicateFilter    </ol>

code statement(s):
df.setKeepMode(DuplicateFilter.KM_USE_LAST_OCCURRENCE)

****************************** #225 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31478192

comment sentences(s):
You  can  use  a  boolean  query  like  :  must

code statement(s):
Query luceneQuery=b.bool().must(b.keyword().onField("fieldName").matching("term1").createQuery()).must(b.keyword().onField("fieldName").matching("term2").createQuery()).should(b.keyword().onField("fieldName").matching("term3").createQuery()).except(b.keyword().onField("fieldName").matching("term4").createQuery()).createQuery();


****************************** #226 ******************************
StackOverflow URL: https://stackoverflow.com/questions/1827116

comment sentences(s):
This  outputs  :  <blockquote>  Pubblichiamo  la  presentazione  di  IBM  riguardante  DB2  per  i  vari  sistemi  operativiLinux  ,  UNIX  e  Windows  .

code statement(s):
"Pubblichiamo la presentazione di IBM riguardante DB2 per i vari sistemi operativi" + "Linux, UNIX e Windows.\r\n\r\nQuesto documento sta sulla piattaforma KM e lo potete" + "scaricare a questo &lt;a href=\'https://sfkm.griffon.local/sites/BSF%20KM/BSF/CC%20T/Specifiche/Eventi2008/IBM%20DB2%20for%20Linux,%20UNIX%20e%20Windows.pdf\' target=blank&gt;link&lt;/a&gt;."

****************************** #227 ******************************
StackOverflow URL: https://stackoverflow.com/questions/1827116

comment sentences(s):
Questo  documento  sta  sulla  piattaforma  KM  e  lo

code statement(s):
"Pubblichiamo la presentazione di IBM riguardante DB2 per i vari sistemi operativi" + "Linux, UNIX e Windows.\r\n\r\nQuesto documento sta sulla piattaforma KM e lo potete" + "scaricare a questo &lt;a href=\'https://sfkm.griffon.local/sites/BSF%20KM/BSF/CC%20T/Specifiche/Eventi2008/IBM%20DB2%20for%20Linux,%20UNIX%20e%20Windows.pdf\' target=blank&gt;link&lt;/a&gt;."

****************************** #228 ******************************
StackOverflow URL: https://stackoverflow.com/questions/1742245

comment sentences(s):
My  bet  is  on  the  difference  in  idf  between  the  two  cases ( both  numDocs  and  docFreq  are  different ) .

code statement(s):
ScoreDoc[] scoreDocs=hits.scoreDocs;

for(ScoreDoc scoreDoc : scoreDocs)

****************************** #229 ******************************
StackOverflow URL: https://stackoverflow.com/questions/1133280

comment sentences(s):
Instead  ,  org.hibernate.search.jpa.FullTextQuery  has  the  setProject() method  that  I  needed  .

code statement(s):
query2.setProjection("id")

****************************** #230 ******************************
StackOverflow URL: https://stackoverflow.com/questions/1133280

comment sentences(s):
Here  is  the  resulting  code ( with  fully  qualified  class  names ) :  query2  does  the  projection  and  all  is  well  !

code statement(s):
query2=fullTextSession.createFullTextQuery(query,SampleBean.class)

****************************** #231 ******************************
StackOverflow URL: https://stackoverflow.com/questions/379345

comment sentences(s):
If  they  are  phrases  ,  you  will  need  to  use  PhraseQuery  instead  of  TermQuery  .

code statement(s):
add(new TermQuery(new Term("Author","a1")),BooleanClause.Occur.MUST)
add(new TermQuery(new Term("title","t1")),BooleanClause.Occur.MUST)
add(new TermQuery(new Term("Author","a2")),BooleanClause.Occur.MUST)
add(new TermQuery(new Term("title","t2")),BooleanClause.Occur.MUST)
add(new TermQuery(new Term("Author","a3")),BooleanClause.Occur.MUST)
add(new TermQuery(new Term("title","t3")),BooleanClause.Occur.MUST)

****************************** #232 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3737629

comment sentences(s):
Alternatively  ,  if  you  have  your  own  unique  ID  field  ,  you  can  do

code statement(s):
new Term("MyIDField","ID to delete")

****************************** #233 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3412619

comment sentences(s):
NET  version  rather  than  the  Java  version  .

code statement(s):
new QueryParser(LuceneVersion,"content",new StandardAnalyzer(LuceneVersion))

****************************** #234 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3412619

comment sentences(s):
Since  Lucene.NET  is  a  port  of  the  Java  version  ,  I  suspect  you  could  use  the  same  approach  for  the  Java  version  .

code statement(s):
new QueryParser(LuceneVersion,"content",new StandardAnalyzer(LuceneVersion))

****************************** #235 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3362854

comment sentences(s):
You  could  use  the  above  to  determine  to  collapse  fuzzy  duplicate  strings  into  one  ``  master  ''  string  and  then  index  .

code statement(s):
GetSimilarity(string1,string2)

****************************** #236 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3348457

comment sentences(s):
I  added  the  -LSB-  Field ( Index.Tokenized  ,  Store  =  Store.Yes ) -RSB-  -  attribute  to  the  IsDeleted  property  ,  and  added  this  clause  to  any  query  inbound  :  I  knew  it  was  something  simple  :  )

code statement(s):
q="(" + userQuery + ") AND IsDeleted:False"

****************************** #237 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3328715

comment sentences(s):
You  can  <strong>  append  </strong>  to  the  index  thus  :  The  false  flag  at  the  end  tells  the  IndexWriter  to  open  in  append  mode ( i.e.  not  overwrite ) .

code statement(s):
new IndexWriter(IndexFileLocation,Analyzer,false)

****************************** #238 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3029239

comment sentences(s):
If  you  want  to  lookup  a  file  on  the  RFS ( real  file  system ) under  the  WEB-INF  folder

code statement(s):
pageContext.getServletContext().getRealPath("/") + "WEB-INF" + java.io.File.separator+ "index"

****************************** #239 ******************************
StackOverflow URL: https://stackoverflow.com/questions/3029239

comment sentences(s):
can  get  the  path  via  :  and  then  use  the  common  java  file  methods  to  read  it

code statement(s):
pageContext.getServletContext().getRealPath("/") + "WEB-INF" + java.io.File.separator+ "index"

****************************** #240 ******************************
StackOverflow URL: https://stackoverflow.com/questions/2589041

comment sentences(s):
does  this  for  you  ,  for  example  The  above  query  will  count  all  hits  ,  but  return  only  10

code statement(s):
totalHits=topDocs.totalHits

****************************** #241 ******************************
StackOverflow URL: https://stackoverflow.com/questions/2268994

comment sentences(s):
Or  you  can  done  it  by  the  hand  ,  using  only  only  java  by  then  sort  this  file  and  sum  all  duplicate  lines ( manually  or  from  some  command  line  utility ) ,  it  will  be  fast  as  possible  .

code statement(s):
resultFile.println(StringUtils.join(" ",triple))

****************************** #242 ******************************
StackOverflow URL: https://stackoverflow.com/questions/2075366

comment sentences(s):
You  'll  need  to  use  a  BooleanQuery  .

code statement(s):
filterQuery.Add(query1,BooleanClause.Occur.MUST)
filterQuery.Add(query1,BooleanClause.Occur.MUST)

****************************** #243 ******************************
StackOverflow URL: https://stackoverflow.com/questions/5649105

comment sentences(s):
Each  1  has  an  index  ,  that  is  equal  to  document  id  So  1001001  means  that  documents  with  position  0  ,  3  and  6  in  index  match  your  search  .

code statement(s):
new IndexSearcher(indexPath)

****************************** #244 ******************************
StackOverflow URL: https://stackoverflow.com/questions/5528005

comment sentences(s):
Index  your  paths  using  KeywordAnalyzer  ,  and  your  data  using  StandardAnalyzer  .

code statement(s):
Add(new PrefixQuery("Path","questions\\text\\testing\\"),BooleanClause.Occur.MUST)

****************************** #245 ******************************
StackOverflow URL: https://stackoverflow.com/questions/5423557

comment sentences(s):
The  resulting  working  code  was  a  change  in  the  results  :  I  changed  from  multiple  fields  to  a  single  field  on  the  query  since  the  pagename  would  never  be  useful  in  the  summary  this  is  being  used  for  and  changed  from  a  Formatter  to  a  SimpleFormatter

code statement(s):
field.StringValue()
field.StringValue()

****************************** #246 ******************************
StackOverflow URL: https://stackoverflow.com/questions/5199449

comment sentences(s):
``  filename  ''  is  stored  but  ``  contents  ''  is  n't  ,  which  is  why  you  see  them  behaving  differently  :

code statement(s):
new Field("contents",reader,Field.TermVector.WITH_POSITIONS_OFFSETS)

****************************** #247 ******************************
StackOverflow URL: https://stackoverflow.com/questions/5099709

comment sentences(s):
It  would  require  updating  both  fields  as  the  tag  list  changes  of  course  ,  but  the  overhead  may  be  worth  it  .

code statement(s):
new Field("tags","{personal}|{favorite}")

****************************** #248 ******************************
StackOverflow URL: https://stackoverflow.com/questions/4841483

comment sentences(s):
Hibernate  search  exposes  this  functionality ( FullTextQuery.sort ) .

code statement(s):
searchQuery.setSort(sort)

****************************** #249 ******************************
StackOverflow URL: https://stackoverflow.com/questions/4693317

comment sentences(s):
You  should  keep  the  writer  always  open  ,  but  do  n't  persist  the  reader/searcher  .

code statement(s):
IndexSearcher srch=new IndexSearcher(writer.getReader());


****************************** #250 ******************************
StackOverflow URL: https://stackoverflow.com/questions/4693317

comment sentences(s):
When  you  need  a  searcher  just  do  This  way  the  searcher  will  get  the  most  recent  changes  ,  even  if  they  are  n't  flushed  to  disk  yet ( giving  you  the  best  of  both  worlds ) .

code statement(s):
IndexSearcher srch=new IndexSearcher(writer.getReader());


****************************** #251 ******************************
StackOverflow URL: https://stackoverflow.com/questions/4357399

comment sentences(s):
take  a  look  at  the  very  simple  example  in  your  case  ,  you  would  do  something  like  this  to  create  the  document  ,  that  would  get  saved  in  the  index  .

code statement(s):
doc.add(new Field("ReqName",ReqName,Field.Store.YES,Field.Index.NOT_ANALYZED))
doc.add(new Field("Type",Type,Field.Store.YES,Field.Index.NOT_ANALYZED))
doc.add(new Field("Priority",Priority,Field.Store.YES,Field.Index.NOT_ANALYZED))
doc.add(new Field("Assigned",Assigned,Field.Store.YES,Field.Index.NOT_ANALYZED))
doc.add(new Field("Due",Due,Field.Store.YES,Field.Index.NOT_ANALYZED))
doc.add(new Field("Status",Status,Field.Store.YES,Field.Index.NOT_ANALYZED))

****************************** #252 ******************************
StackOverflow URL: https://stackoverflow.com/questions/4357399

comment sentences(s):
the  document  ,  that  would  get  saved  in  the  index

code statement(s):
doc.add(new Field("ReqName",ReqName,Field.Store.YES,Field.Index.NOT_ANALYZED))
doc.add(new Field("ReqDescription",ReqDescription,Field.Store.YES,Field.Index.ANALYZED))
doc.add(new Field("Type",Type,Field.Store.YES,Field.Index.NOT_ANALYZED))
doc.add(new Field("Priority",Priority,Field.Store.YES,Field.Index.NOT_ANALYZED))
doc.add(new Field("Assigned",Assigned,Field.Store.YES,Field.Index.NOT_ANALYZED))
doc.add(new Field("Due",Due,Field.Store.YES,Field.Index.NOT_ANALYZED))
doc.add(new Field("Status",Status,Field.Store.YES,Field.Index.NOT_ANALYZED))

****************************** #253 ******************************
StackOverflow URL: https://stackoverflow.com/questions/8209435

comment sentences(s):
You  can  combine  multiple  queries  using  BooleanQuery  ,  and  have  Occur.Should ( meaning  OR ) .

code statement(s):
query=new BooleanQuery()

****************************** #254 ******************************
StackOverflow URL: https://stackoverflow.com/questions/8071184

comment sentences(s):
Guidance  for  settings  above  can  be  found  from  http://www.elasticsearch.org/guide/reference/java-api/client.html

code statement(s):
TransportClient client=new TransportClient(s);


****************************** #255 ******************************
StackOverflow URL: https://stackoverflow.com/questions/7744724

comment sentences(s):
You  're  using  a  standard  analyzer  for  your  query  parser

code statement(s):
MultiFieldQueryParser parser=new MultiFieldQueryParser(Version.LUCENE_30,getSearchFields(),new KeywordAnalyzer(Version.LUCENE_30));


****************************** #256 ******************************
StackOverflow URL: https://stackoverflow.com/questions/7744724

comment sentences(s):
yes  your  query  will  be  analyzed  with  a  standard  analyzer

code statement(s):
MultiFieldQueryParser parser=new MultiFieldQueryParser(Version.LUCENE_30,getSearchFields(),new KeywordAnalyzer(Version.LUCENE_30));


****************************** #257 ******************************
StackOverflow URL: https://stackoverflow.com/questions/7744724

comment sentences(s):
Just  switch  to  using  a  keyword  analyzer  :  You  may  want  to  use  a  PerFieldAnalyzerWrapper  if  your  other  fields  are  n't  keywords  .

code statement(s):
MultiFieldQueryParser parser=new MultiFieldQueryParser(Version.LUCENE_30,getSearchFields(),new KeywordAnalyzer(Version.LUCENE_30));


****************************** #258 ******************************
StackOverflow URL: https://stackoverflow.com/questions/7529541

comment sentences(s):
I  ended  up  changing  the  way  Lucene  was  storing  the  project.id  :

code statement(s):
new Field("project.id",projectId.ToString(),Field.Store.NO,Field.Index.ANALYZED)

****************************** #259 ******************************
StackOverflow URL: https://stackoverflow.com/questions/7425892

comment sentences(s):
The  field  needs  to  be  analyzed  as  well  as  term  vectors  need  to  be  enabled  .

code statement(s):
new Field("content",value,Field.Store.YES,Field.Index.ANALYZED,Field.TermVector.YES)

****************************** #260 ******************************
StackOverflow URL: https://stackoverflow.com/questions/7425892

comment sentences(s):
You  can  disable  storing  if  you  do  not  plan  to  retrieve  that  field  from  the  index  .

code statement(s):
new Field("content",value,Field.Store.YES,Field.Index.ANALYZED,Field.TermVector.YES)

****************************** #261 ******************************
StackOverflow URL: https://stackoverflow.com/questions/7401726

comment sentences(s):
It  seems  the  answer  is  registering  indexes  per-query  execution  using  the  context  of  query  .

code statement(s):
QueryExecution qe=QueryExecutionFactory.create(query,model);


****************************** #262 ******************************
StackOverflow URL: https://stackoverflow.com/questions/7191583

comment sentences(s):
This  means  that  any  result  must  have  either  ID  =  a  ,  b  ,  or  c.

code statement(s):
new Term("ID","b")

****************************** #263 ******************************
StackOverflow URL: https://stackoverflow.com/questions/7094576

comment sentences(s):
I  have  found  the  answer  myself  ,  so  I  thought  I  would  share  it  :  And  obviously  I  have  all  the  properties  of  the  set  's  directory  from  DirectoryInfo  object  too  .

code statement(s):
DirectoryInfo dir=set.IndexDirectory;


****************************** #264 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6782573

comment sentences(s):
I  think  you  need  to  do  more  than  just  connect() to  the  URL  to  issue  an  HTTP  GET  .

code statement(s):
url=new java.net.URL("http://***********/GenerateThumbnail?url=http://money.cnn.com/2011/07/20/news/economy/debt_ceiling_deal/index.htm?cnn=yes")

****************************** #265 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6782573

comment sentences(s):
Perhaps  for  the  HTTP  protocol  the  java  URL  library  does  n't  see  a  need  to  open  a  stateful  connection  and  therefore  does  n't  connect  until  the  data  is  requested ( as  opposed  to  if  URL  was  used  to  access  something  like  an  FTP  address ) .

code statement(s):
connection=url.openConnection()

****************************** #266 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6729358

comment sentences(s):
See  Lucene  Documentation  :  <blockquote>  public  final  class  StandardTokenizer  extends  Tokenizer  A  grammar-based  tokenizer  constructed  with  JFlex  This  should  be  a  good  tokenizer  for  most  European-language  documents  :  Splits  words  at  punctuation  characters  ,  removing  punctuation  .

code statement(s):
TokenStream stream=new StandardTokenizer(Version.LUCENE_32,reader);


****************************** #267 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6225111

comment sentences(s):
You  can  then  play  with  the  boost  factor  at  query  time  to  search  both  fields  but  give  the  one  with  numbers  a  low  priority  .

code statement(s):
Query luceneQuery=mythQB.phrase().onField("history").matching("Thou shalt not kill").createQuery();


****************************** #268 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6225111

comment sentences(s):
As  for  the  phrase  search  ,  simply  use  a  PhraseQuery  by  Lucene  or  use  the  more  friendly  Hibernate  Search  DSL  ,  The  whole  doc  for  the  query  DSL  is  here

code statement(s):
Query luceneQuery=mythQB.phrase().onField("history").matching("Thou shalt not kill").createQuery();


****************************** #269 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6225111

comment sentences(s):
for  the  phrase  search  ,  simply  use  a  PhraseQuery  by  Lucene  or  use  the  more  friendly  Hibernate  Search  DSL

code statement(s):
mythQB.phrase().onField("history").matching("Thou shalt not kill").createQuery()

****************************** #270 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6028374

comment sentences(s):
See  http://docs.jboss.org/hibernate/stable/search/reference/en-US/html_single/#query-filter  You  can  pass  parameters  to  the  filter  when  you  enable  them  ,  eg  You  can  pass  as  many  parameters  you  like  and  also  pass  any  parameter  type  you  want ( you  will  just  have  to  cast  appropriately  in  the  filter  implementation ) .

code statement(s):
fullTextQuery.enableFullTextFilter("version").setParameter("max",1001)

****************************** #271 ******************************
StackOverflow URL: https://stackoverflow.com/questions/6028374

comment sentences(s):
Within  the  <em>  Filter  </em>  you  could  use  a  <em>  NumericRangeQuery  </em>  .

code statement(s):
fullTextQuery.enableFullTextFilter("version")

****************************** #272 ******************************
StackOverflow URL: https://stackoverflow.com/questions/10301564

comment sentences(s):
in  most  cases  you  can  simply  use  wildcard  queries  with  a  leading  wildcard  *  burger  .

code statement(s):
setAllowLeadingWildcard(true)

****************************** #273 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9844592

comment sentences(s):
Please  add  while  indexing  file  here  doc  is  of  type  org.apache.lucene.document.Document  .

code statement(s):
doc.add(new Field("contents",result,Field.Store.COMPRESS,Field.Index.ANALYZED,Field.TermVector.WITH_POSITIONS_OFFSETS))

****************************** #274 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9844592

comment sentences(s):
use  com.java.search.HighlighterUtil.getFragmentsWithHighlightedTerms

code statement(s):
new Field("contents",result,Field.Store.COMPRESS,Field.Index.ANALYZED,Field.TermVector.WITH_POSITIONS_OFFSETS)

****************************** #275 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9844592

comment sentences(s):
-LRB-  Analyzer  analyzer  ,  Query  query  ,  String  fieldName  ,  String  fieldContents  ,  int  fragmentNumber  ,  int  fragmentSize  )

code statement(s):
new Field("contents",result,Field.Store.COMPRESS,Field.Index.ANALYZED,Field.TermVector.WITH_POSITIONS_OFFSETS)

****************************** #276 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9816179

comment sentences(s):
<  pre  class  =  ``  lang-cs  prettyprint-override  ''  >  In  an  up-to-date  version  you  could  use  NumericFields/NumericRangeQuery  for  better  performance  .

code statement(s):
rq=new RangeQuery(new Term("date","10660101"),new Term("date","19990101"),true)

****************************** #277 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9581479

comment sentences(s):
Before  lucene  3.x  ,  You  can  use  RangeQuery  like  following  :  see  the  tutorial  for  more  details  :  http://www.avajava.com/tutorials/lessons/how-do-i-perform-a-range-query.html  How  do  I  perform  a  range  query  ?

code statement(s):
Query query=queryParser.parse(searchString);


****************************** #278 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9507992

comment sentences(s):
<strong>  Intersection  of  two  queries  </strong>  You  seem  to  be  happy  with  you  conjuctive  query  on  the  default  field  resultset  ,  and  by  your  disjunctive  query  on  all  fields  scoring  .

code statement(s):
Query mainQuery, filterQuery;


****************************** #279 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9507992

comment sentences(s):
<ul>  2  terms  =  >  ceil ( 2  *  3  /  4 ) =  2  :  all  clauses  must  match    3  terms  =  >  ceil ( 3  *  3  /  4 ) =  3  :  3/4  clauses  must  match ( the  new  clauses  is  required  ,  <strong>  less  </strong>  results )   4  terms  =  >  ceil ( 4  *  3  /  4 ) =  3  :  3/4  clauses  must  match ( one  of  the  clauses  is  optional  ,  <strong>  more  </strong>  results )   5  terms  =  >  ceil ( 5  *  3  /  4 ) =  4  :  4/5  clauses  must  match ( maybe  more  ,  maybe  less  results  ,  depending  on  the  co-occurrences  of  the  new  term  with  the  4  first  ones )   </ul>  Anyway  ,  with  this  feature  ,  the  only  way  for  the  number  of  results  to  shrink  as  the  number  of  clauses  increases  is  to  have  a  purely  conjunctive  query  .

code statement(s):
query=new BooleanQuery()

****************************** #280 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9495613

comment sentences(s):
You  basically  just  need  to  get  the  Hibernate  Search  jar  file  and  add  it  to  your  project  ,  then  annotate  the  entities  you  want  to  have  indexed  with  @Indexed  and  the  fields  you  want  to  index  with  @Field  .

code statement(s):
Search.getFullTextEntityManager(em)

****************************** #281 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9495613

comment sentences(s):
the  entities  you  want  to  have  indexed  with  @Indexed  and  the  fields

code statement(s):
fullTextEntityManager.createIndexer()

****************************** #282 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9495613

comment sentences(s):
I  think  it  ca  n't  cause  the  documentation  says  it  builds  the  index  when  the  entities  are  updated ( which  are  never  the  case  in  my  WebService ) .

code statement(s):
fullTextEntityManager.createIndexer()

****************************** #283 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9278703

comment sentences(s):
Yes  ,  this  works  You  have  to  remember  to  index  the  field  with  TermVector.YES  in  your  hibernate  search  annotation  for  the  field  .

code statement(s):
TermFreqVector freq=indexReader.getTermFreqVector((Integer)dId[0],"description");


****************************** #284 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9218080

comment sentences(s):
I  might  be  missing  something  ,  but  ...  You  do  n't  need  a  custom  tokenizer  to  associate  additional  information  to  a  Lucene  document  .

code statement(s):
new Field("fname","Joe",Field.Store.YES,Field.Index.ANALYZED)
new Field("job","Plumber",Field.Store.YES,Field.Index.ANALYZED)

****************************** #285 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9218080

comment sentences(s):
Just  store  is  as  an  unanalyzed  field  .

code statement(s):
new Field("fname","Joe",Field.Store.YES,Field.Index.ANALYZED)
new Field("job","Plumber",Field.Store.YES,Field.Index.ANALYZED)
new Field("link","http://www.example.com",Field.Store.YES,Field.Index.NO)

****************************** #286 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9218080

comment sentences(s):
You  can  then  get  the  ``  link  ''  field  just  like  any  other  field  .

code statement(s):
new Field("link","http://www.example.com",Field.Store.YES,Field.Index.NO)

****************************** #287 ******************************
StackOverflow URL: https://stackoverflow.com/questions/9218080

comment sentences(s):
Also  ,  if  you  did  need  a  custom  tokenizer  ,  then  you  would  definitely  need  a  custom  analyzer  to  implement  it  ,  for  both  the  index  building  and  searching  .

code statement(s):
new Field("fname","Joe",Field.Store.YES,Field.Index.ANALYZED)
new Field("job","Plumber",Field.Store.YES,Field.Index.ANALYZED)

****************************** #288 ******************************
StackOverflow URL: https://stackoverflow.com/questions/8928494

comment sentences(s):
For  Numeric  stored  as  binary  value  ,  you  need  to  get  by  <em>  doc.getBinaryValue ( fieldName ) </em>  you  will  get  <strong>  byte  -LSB-  -RSB-  </strong>  as  return  value  which  you  will  have  to  convert  it  into  your  appropriate  numeric  value  .

code statement(s):
addField(fieldName,doc.get(fieldName))

****************************** #289 ******************************
StackOverflow URL: https://stackoverflow.com/questions/8928494

comment sentences(s):
<strong>  byte  -LSB-  -RSB-  </strong>  as  return  value

code statement(s):
ByteBuffer buff=ByteBuffer.wrap(doc.getBinaryValue(fieldName));


****************************** #290 ******************************
StackOverflow URL: https://stackoverflow.com/questions/8664210

comment sentences(s):
I  was  required  to  annotate  the  field  declaration  as  <strong>  NOT_ANALYZED  : ( Index  the  property  's  value  without  using  an  Analyzer  ,  so  it  can  be  searched ) </strong>

code statement(s):
@SearchableProperty(index=Index.NOT_ANALYZED) private String field_name;


****************************** #291 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13377258

comment sentences(s):
<br>  word1  <br>  word2  <br>  word3  </blockquote>  This  page  explains  it  a  bit  in  context  of  a  Lucene  index

code statement(s):
indexDictionary(new LuceneDictionary(my_luceneReader,my_fieldname))

****************************** #292 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13377258

comment sentences(s):
Adding  Words  to  the  Dictionary  We  can  add  the  words  coming  from  a  Lucene  Index ( more  precisely  from  a  set  of  Lucene  fields ) ,  and  from  a  text  file  with  a  list  of  words

code statement(s):
indexDictionary(new LuceneDictionary(my_luceneReader,my_fieldname))

****************************** #293 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13377258

comment sentences(s):
Example  :  we  can  add  all  the  keywords  of  a  given  Lucene  field  of  my  index  .

code statement(s):
indexDictionary(new LuceneDictionary(my_luceneReader,my_fieldname))

****************************** #294 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13348846

comment sentences(s):
Are  you  adding  your  Fields  with  the  Field.TermVector.YES  option  enabled  ?

code statement(s):
new Field("value",documentContents,Field.Store.YES,Field.Index.ANALYZED,Field.TermVector.YES)

****************************** #295 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12863385

comment sentences(s):
If  there  is  only  1  document  matching  that  search  ,  which  seems  likely  enough  ,  that  probably  explains  why  you  're  getting  nothing ( having  skipped  the  first  and  only  result  ,  at  index  0 ) .

code statement(s):
query.setFirstResult(0).setMaxResults(100)

****************************** #296 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12818752

comment sentences(s):
the  string  based  search  string  yourself  using  <em>  DateTools  </em>

code statement(s):
monthQb.range().onField("startTS").ignoreFieldBridge().from(DateTools.dateToString(from,DateTools.Resolution.MILLISECOND)).to(DateTools.dateToString(to,DateTools.Resolution.MILLISECOND))

****************************** #297 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12789416

comment sentences(s):
you  could  try  just  using  TermQuery  instead  of  PrefixQuery

code statement(s):
PrefixQuery pquery=new PrefixQuery(new Term("title","special"));


****************************** #298 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12744085

comment sentences(s):
This  is  how  KStemmer  is  used  inside  Lucene  :  http://svn.apache.org/repos/asf/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemFilter.java  Note  ,  that  KStemmer  class  is  part  of  Lucene  's  current  trunk ( org.apache.lucene.analysis.en ) :  http://svn.apache.org/repos/asf/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java

code statement(s):
private final KStemmer stemmer=new KStemmer();


****************************** #299 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12717591

comment sentences(s):
<strong>  Indexing  Custom  Fields  </strong>  When  defining  a  FieldBridge  you  get  to  add  as  many  fields  as  you  like  to  the  indexed  Document  ,  and  you  can  name  each  of  them  as  you  like  .

code statement(s):
setProjection("myField1","myField2")

****************************** #300 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12383955

comment sentences(s):
Since  ,  you  are  working  with  tokenized  string  ,  every  word  is  a  separate  term  .

code statement(s):
new Term(string - field - name,"very")
new Term(string - field - name,"good")

****************************** #301 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12267147

comment sentences(s):
The  lock  file  is  used  to  prevent  2  IndexWriter  opened  on  the  same  index  ,  whether  they  are  in  the  same  process  or  not  .

code statement(s):
IndexWriter writer=new IndexWriter("Path to index here",new WhitespaceAnalyzer());


****************************** #302 ******************************
StackOverflow URL: https://stackoverflow.com/questions/12076391

comment sentences(s):
Try  using  Term  Query  probably  your  field  is  ``  content  ''  or  ''  _  content  ''  .

code statement(s):
Term term=new Term("field","searchstring");


****************************** #303 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11977029

comment sentences(s):
I  have  tested  the  Lucene.Net.Store.Azure  1.0.5.1  with  Lucene.Net  3.0.3  which  worked  for  me  .

code statement(s):
Lucene.Net.Util.Version version=Lucene.Net.Util.Version.LUCENE_30;


****************************** #304 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11977029

comment sentences(s):
a  Windows  Azure  Worker  Role  in  VS2010    Included  Lucene.NET.Store.Azure ( 1.0.5.1  )

code statement(s):
Microsoft.WindowsAzure.CloudStorageAccount cloudAccount=Microsoft.WindowsAzure.CloudStorageAccount.FromConfigurationSetting("CloudStorageSetting");


****************************** #305 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11977029

comment sentences(s):
from  here ( which  has  dependency  on  Lunece.NET  2.9.4.1  and  above ) using  VS  Package  Manager  2.1  PM  >  Install-Package  Lucene.Net.Store.Azure    After  that  I  updated  Lucene.net  to  3.0.3  RC  from  here  which  removed  Lucene.net  2.9.4.1  and  installed  3.0.3  bits  3.1  PM  >  Install-Package  Lucene.Net  -  Pre    Verified  that  I  have  latest  bits  and  all  the  dependency  set  in  my  project  ,  I  added  the  following  test  code  in  my  worker  role

code statement(s):
Lucene.Net.Util.Version version=Lucene.Net.Util.Version.LUCENE_30;


****************************** #306 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
NumericFields  are  indexed  using  a  trie  structure  .

code statement(s):
new Field("normal","",Field.Store.YES,Field.Index.ANALYZED)

****************************** #307 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
Within  Lucene  ,  each  numeric  value  is  indexed  as  a  trie  structure  ,  where  each  term  is  logically  assigned  to  larger  and  larger  pre-defined  brackets ( which  are  simply  lower-precision  representations  of  the  value  )

code statement(s):
SetValue("one")
SetValue("one")
SetValue("one")
SetValue("one")
SetValue("one")

****************************** #308 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
Smaller  precisionStep  values  result  in  larger  number  of  brackets  ,  which  consumes  more  disk  space  in  the  index  but  may  result  in  faster  range  search  performance  .

code statement(s):
number=new NumericField("number",Field.Store.YES,true)

****************************** #309 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
faster  range  search  performance

code statement(s):
Search(rangeQ)
Search(rangeQ)
Search(rangeQ)

****************************** #310 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
int  ,  Field.Store  ,  boolean

code statement(s):
SetIntValue(1)
SetIntValue(2)
SetIntValue(13)
SetIntValue(2000)
SetIntValue(9999)

****************************** #311 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
If  the  cardinality  is  <  100  ,  it  is  fair  to  use  Integer.MAX  _  VALUE  ,  which  produces  one  term  per  value  .

code statement(s):
SetValue("one")
SetValue("one")
SetValue("one")
SetValue("one")
SetValue("one")

****************************** #312 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
...  </blockquote>  More  details  on  the  precision  step  available  in  the  NumericRangeQuery  documentation  :  <blockquote>  Good  values  for  precisionStep  are  depending  on  usage  and  data  type  :  ?

code statement(s):
new Field("normal","",Field.Store.YES,Field.Index.ANALYZED)

****************************** #313 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
Ideal  value  in  most  cases  for  32  bit  data  types ( int  ,  float ) is  4  .  ?

code statement(s):
SetIntValue(1)
SetIntValue(2)
SetIntValue(13)
SetIntValue(2000)
SetIntValue(9999)

****************************** #314 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
32  for  int/float  produces  one  token  per  value  in  the  index  and  querying  is  as  slow  as  a  conventional  TermRangeQuery  .

code statement(s):
new Field("normal","",Field.Store.YES,Field.Index.ANALYZED)

****************************** #315 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
But  it  can  be  used  to  produce  fields  ,  that  are  solely  used  for  sorting ( in  this  case  simply  use  Integer.MAX  _  VALUE  as  precisionStep ) .

code statement(s):
Field regular=new Field("normal","",Field.Store.YES,Field.Index.ANALYZED);


****************************** #316 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
These  fields  have  one  term  per  value  and  therefore  also  work  with  term  enumeration  for  building  distinct  lists ( e.g.  facets  /  preselected  values  to  search  for ) .

code statement(s):
new Field("normal","",Field.Store.YES,Field.Index.ANALYZED)

****************************** #317 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
value  and  therefore  also  work  with  term  enumeration  for  building  distinct  lists ( e.g.  facets  /  preselected  values  to  search  for  )

code statement(s):
new Field("normal","",Field.Store.YES,Field.Index.ANALYZED)
SetIntValue(1)
SetIntValue(2)
SetIntValue(13)
SetIntValue(2000)
SetIntValue(9999)

****************************** #318 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
Sorting  is  also  possible  with  range  query  optimized  fields  using  one  of  the  above  precisionSteps  .

code statement(s):
SetValue("one")
SetValue("one")
SetValue("one")
SetValue("one")
SetValue("one")

****************************** #319 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
</blockquote>  <strong>  EDIT  </strong>  little  sample  ,  the  index  produced  by  this  will  show  terms  with  value  8192  ,  9984  ,  1792  ,  etc  in  luke  ,  but  using  a  range  that  would  include  them  in  the  query  doesnt  produce  results  :  <  pre  class  =  ``  lang-cs  prettyprint-override  ''  >

code statement(s):
regular=new Field("normal","",Field.Store.YES,Field.Index.ANALYZED)

****************************** #320 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11890571

comment sentences(s):
the  query  doesnt  produce  results

code statement(s):
new Field("normal","",Field.Store.YES,Field.Index.ANALYZED)

****************************** #321 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11521670

comment sentences(s):
Just  use  lucene  AddDocument  method  ,  something  like  this  :

code statement(s):
AddDocument(luceneDoc)

****************************** #322 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11269749

comment sentences(s):
``  abc  def  ghi  ''  ~  8  &  &  ``  abc  def  ''  ~  3  &  &  ``  def  ghi  ''  ~  5  is  different  than  ??

code statement(s):
new SpanNearQuery(new SpanQuery[]{new SpanTermQuery(new Term(FIELD,"abc")),new SpanTermQuery(new Term(FIELD,"def"))},3,true)

****************************** #323 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11269749

comment sentences(s):
abc  def  ghi

code statement(s):
{new SpanTermQuery(new Term(FIELD,"abc")),new SpanTermQuery(new Term(FIELD,"def"))}

****************************** #324 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11269749

comment sentences(s):
``  abc  def  ''

code statement(s):
{new SpanTermQuery(new Term(FIELD,"abc")),new SpanTermQuery(new Term(FIELD,"def"))}

****************************** #325 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11269749

comment sentences(s):
``  def  ghi  ''  ~  5

code statement(s):
new SpanNearQuery(new SpanQuery[]{spanNear,new SpanTermQuery(new Term(FIELD,"ghi"))},5,true)

****************************** #326 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11269749

comment sentences(s):
abc  ,1,2,3  ,  def  ,1,2,3,4,5  ,

code statement(s):
{new SpanTermQuery(new Term(FIELD,"abc")),new SpanTermQuery(new Term(FIELD,"def"))}

****************************** #327 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11227613

comment sentences(s):
I  think  you  could  boost  the  field  with  the  different  values  at  index  time  :  You  need  to  enable  norms  for  this  to  work  .

code statement(s):
Field mysqlf=new Field("skill","mysql",Field.Store.YES,Field.Index.ANALYZED);


****************************** #328 ******************************
StackOverflow URL: https://stackoverflow.com/questions/11227613

comment sentences(s):
the  different  values  at  index  time

code statement(s):
new Field("skill","mysql",Field.Store.YES,Field.Index.ANALYZED)
new Field("skill","mysql",Field.Store.YES,Field.Index.ANALYZED)

****************************** #329 ******************************
StackOverflow URL: https://stackoverflow.com/questions/16306137

comment sentences(s):
<br>  Something  along  the  lines  of  :  Take  a  look  at  the  Migration  Guide  for  more  info  ,  there  's  a  section  about  IndexReader  -  >  AtomicReader  .

code statement(s):
for(FieldInfo info : atomicReader.getFieldInfos().iterator())

****************************** #330 ******************************
StackOverflow URL: https://stackoverflow.com/questions/15730250

comment sentences(s):
We  use  MultiFieldQueryParser  only  when  we  want  to  search  the  <strong>  same  keyword ( s ) </strong>  in  multiple  fields  .

code statement(s):
QueryParser cityQP=new QueryParser(Version.LUCENE_CURRENT,"city",analyzer);

QueryParser titleQP=new QueryParser(Version.LUCENE_CURRENT,"title",analyzer);


****************************** #331 ******************************
StackOverflow URL: https://stackoverflow.com/questions/15376571

comment sentences(s):
Lucene  's  IndexReader  takes  a  snapshot  of  the  index  ,  either  the  committed  version  when  NRT  is  not  used  or  both  committed  and  uncommitted  version  when  NRT  is  used  .

code statement(s):
IndexReader reader=DirectoryReader.open(indexWriter);


****************************** #332 ******************************
StackOverflow URL: https://stackoverflow.com/questions/15207439

comment sentences(s):
If  you  just  need  to  know  the  terms/frequencies  ,  you  can  just  obtain  the  single  tokens  directly  from  the  analyzer ( you  can  get  the  TF  by  counting  them  ,  e.g.  by  using  a  Map  or  a  Multiset ) .

code statement(s):
TokenStream ts=analyzer.tokenStream(field,new StringReader(text));


****************************** #333 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14892100

comment sentences(s):
Another  answer  comes  from  this  thread ( third  answer ) :  Lucene  4.0  IndexWriter  updateDocument  for  Numeric  Term  Basically  ,  you  create  a  Term  with  your  int  value  like  this  :  Then  you  can  use  this  term  for  searching  ,  or  deleting/updating  your  index  .

code statement(s):
Term term=new Term(field,bytes);


****************************** #334 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14892100

comment sentences(s):
I  've  used  the  NumericRangeFilter  before  for  filtering  IntFields  ,  but  now  I  'm  inclined  to  use  this  approach  and  use  regular  TermsFilter  ,  or  TermQueries  instead  .

code statement(s):
NumericUtils.intToPrefixCoded(value,0,bytes)

****************************** #335 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14887039

comment sentences(s):
Regarding  your  second  question  about  CMIS  and  queries  ,  you  should  be  able  to  query  properties  defined  as  part  of  a  type  through  CMIS  with  no  problem  whatsoever  .

code statement(s):
queryString="select d.*, w.* from cmis:document as d join sc:webable as w on d.cmis:objectId = w.cmis:objectId where w.sc:isActive = True"

****************************** #336 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14887039

comment sentences(s):
Then  your  queries  have  to  do  a  join  like  this  :  In  this  example  ,  sc  :  webable  is  an  aspect  and  the  sc  :  isActive  property  is  defined  on  that  aspect  .

code statement(s):
queryString="select d.*, w.* from cmis:document as d join sc:webable as w on d.cmis:objectId = w.cmis:objectId where w.sc:isActive = True"

****************************** #337 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14782177

comment sentences(s):
the  default  query  parser  handle  some  of  the  same  syntax

code statement(s):
query=defaultParser.parse(queryString)
query=defaultParser.parse(queryString)

****************************** #338 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14782177

comment sentences(s):
Just  implement  parse ( String ) with  that  logic  .

code statement(s):
parse(queryString)
parse(queryString)
parse(queryString)

****************************** #339 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14683447

comment sentences(s):
you  need  to  get  them  from  the  facetCollector  results  using  the  getSubResults  method

code statement(s):
for(FacetResult res : fc.getFacetResults())
FacetResultNode toplvl=res.getFacetResultNode();


****************************** #340 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14683447

comment sentences(s):
Its  actually  possible  to  get  all  levels  in  the  category  path  this  way  .

code statement(s):
"  " + secondlvl.getLabel().getComponent(1) + " ("+ secondlvl.getValue()+ ")"

****************************** #341 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14683447

comment sentences(s):
With  the  code  snippet  below  you  could  loop  over  all  results  ,  and  all  subresults  to  find  the  category  path  you  are  looking  for

code statement(s):
toplvl.getLabel() + " (" + toplvl.getValue()+ ")"

****************************** #342 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14579031

comment sentences(s):
You  could  extend  AbstractJMSHibernateSearchController  and  have  it  deal  with  these  details  ,  or  have  a  look  at  its  source  which  contains  :  Compared  to  older  versions  3.x  there  are  two  main  design  differences  to  keep  in  mind  :  <ul>  The  Serializer  service  is  pluggable  so  it  needs  to  be  looked  up    Each  index ( identified  by  name ) can  have  an  independent  backend    </ul>  The  serialization  is  now  performed ( by  default ) using  Apache  Avro  as  newer  Lucene  classes  are  not  Serializable  .

code statement(s):
indexManager.getSerializer().toLuceneWorks((byte[])objectMessage.getObject())

****************************** #343 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14579031

comment sentences(s):
Each  index ( identified  by  name  )

code statement(s):
indexManager=factory.getAllIndexesManager().getIndexManager(indexName)

****************************** #344 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14367160

comment sentences(s):
According  to  the  TextField  API  it  is  ``  A  field  that  is  indexed  and  tokenized  ,  without  term  vectors  .  ''

code statement(s):
Field field=new Field("body",bodyString,type);


****************************** #345 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14367160

comment sentences(s):
If  you  wish  to  store  TermVectors  ,  you  should  just  use  a  Field  ,  and  set  it  to  store  TermVectors  in  the  FieldType  .

code statement(s):
type.setStoreTermVectors(true)

****************************** #346 ******************************
StackOverflow URL: https://stackoverflow.com/questions/14115465

comment sentences(s):
Modifying  your  code  for  a  new  example ( uncompiled  ,  but  should  be  clear ) :  To  ensure  the  numeric  field  has  been  stored  ,  use  the  NumericField  constructor  that  allows  you  to  specify  whether  and  how  the  field  should  be  stored  .

code statement(s):
myField=doc.GetFieldable("mynumber").StringValue()

****************************** #347 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13963953

comment sentences(s):
is  used  to  store  DateTime  values

code statement(s):
new TermRangeQuery("CreatedAt",DateTools.DateToString(DateTime.MinValue,DateTools.Resolution.MINUTE),DateTools.DateToString(DateTime.MaxValue,DateTools.Resolution.MINUTE),false,false)

****************************** #348 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13960199

comment sentences(s):
LongDocValuesField  is  somewhat  different  in  nature  from  a  LongField  .

code statement(s):
SortField field=new SortField("LastContactTime",SortField.Type.LONG,false);


****************************** #349 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13869975

comment sentences(s):
Lucene  uses  an  inverted  index  ,  which  makes  certain  kinds  of  queries  ,  including  pure  negation  queries  and  searching  for  nulls  ,  difficult  or  even  impossible  .

code statement(s):
new RangeQuery(FieldName,null,null,true,true)

****************************** #350 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13869975

comment sentences(s):
should  store  a  default  value  in  the  field ( for  instance  ``  NULL  '' ) which  you  can  search  for

code statement(s):
new RangeQuery(FieldName,null,null,true,true)

****************************** #351 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13707912

comment sentences(s):
Given  that  you  do  want  to  catch  the  phrase  ``  red  volvo  ''  exactly  ,  but  never  just  ``  red  ''  or  ``  volvo  ''  ,  then  I  think  you  are  on  the  right  track  with  indexing  it  using  the  keyword  analyzer  .

code statement(s):
Analyzer analyzer=new WhitespaceAnalyzer(Version.LUCENE_36);


****************************** #352 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13707912

comment sentences(s):
I  hesitate  to  recommend  it  ,  but  I  think  the  right  way  to  go  about  this  query  might  be  to  use  a  different  analyzer  to  query  than  the  one  you  use  to  create  the  index  .

code statement(s):
Query query=parser.parse(query,defaultField);


****************************** #353 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13707912

comment sentences(s):
If  the  phrases  indexed  are  of  a  predictable  size  ,  say  2-5  words  ,  then  using  a  ShingleFilter  could  produce  the  terms  you  need  from  a  long  query  to  search  it  as  a  Keyword  .

code statement(s):
search(query,10)

****************************** #354 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13707912

comment sentences(s):
Something  like  this  :  This  will  split  only  on  whitespace  ,  and  then  produce  search  terms  of  1  to  5  tokens  in  length  ,  so  in  the  example  :  ``  I  am  selling  a  red  horse  ''  is  will  produce  the  terms  like  ``  I  ''  ,  ``  am  ''  ,  ``  I  am  ''  ,  ``  red  horse  ''  ,  ``  I  am  selling  ''  ,  ``  am  selling  a  red  horse  ''  ,  etc.  .

code statement(s):
new ShingleAnalyzerWrapper(analyzer,1,5)

****************************** #355 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13584765

comment sentences(s):
When  you  iterate  over  search  results  ,  read  the  document  and  load  the  values  from  it  :

code statement(s):
doc.Get("CreationDate")
doc.get("Directory")

****************************** #356 ******************************
StackOverflow URL: https://stackoverflow.com/questions/13510499

comment sentences(s):
Something  like  this  should  work ( you  need  to  combine  queries  using  <em>  bool  </em> ) :  Something  like  this  .

code statement(s):
Query luceneQuery=qb.bool().should(fuzzyQuery).must(categoryQuery).createQuery();


****************************** #357 ******************************
StackOverflow URL: https://stackoverflow.com/questions/18983337

comment sentences(s):
I  had  the  same  problem  and  indexing  entities  one  by  one  helped  .

code statement(s):
fullTextEntityManager.createIndexer(MyClassOne.class)

****************************** #358 ******************************
StackOverflow URL: https://stackoverflow.com/questions/18947473

comment sentences(s):
My  document  type  is  similar  to  your  processor  type  :  Each  processor  type  shall  be  stored  individually  .

code statement(s):
new Field(TYPE,type,Field.Store.YES,Field.Index.UN_TOKENIZED)

****************************** #359 ******************************
StackOverflow URL: https://stackoverflow.com/questions/18195799

comment sentences(s):
Two  things  :    Creating  indexes  on  every  column  <em>  may  </em>  hurt  performance  down  the  line  ,  as  index  updates  are  not  free  .

code statement(s):
session.createCriteria(MyObject.class).addOrder(Order.desc(sortColumn))

****************************** #360 ******************************
StackOverflow URL: https://stackoverflow.com/questions/18195799

comment sentences(s):
  You  can  sort  with  Hibernate  Criteria  ,  e.g.  :  The  sort  key  columns  do  not  need  to  be  indexed  .

code statement(s):
Criteria c=session.createCriteria(MyObject.class).addOrder(Order.desc(sortColumn));


****************************** #361 ******************************
StackOverflow URL: https://stackoverflow.com/questions/18133916

comment sentences(s):
index  documents

code statement(s):
add(new Field("userName",userName),Field.Store.YES,Field.Index.ANALYZED)
new Field("email",email,Field.Store.YES,Field.Index.ANALYZED)

****************************** #362 ******************************
StackOverflow URL: https://stackoverflow.com/questions/17580925

comment sentences(s):
You  set  it  to  Sort  on  a  field  value  ,  not  on  relevance  ,  so  there  is  no  guarantee  that  the  best  matches  will  be  on  the  first  page  .

code statement(s):
Sort sort=new Sort(SortField.FIELD_SCORE,sortField);


****************************** #363 ******************************
StackOverflow URL: https://stackoverflow.com/questions/17580925

comment sentences(s):
on  a  field  value  ,  not  on  relevance

code statement(s):
new Sort(SortField.FIELD_SCORE,sortField)

****************************** #364 ******************************
StackOverflow URL: https://stackoverflow.com/questions/17580925

comment sentences(s):
You  can  sort  by  Relevance  first  ,  then  on  your  field  value  ,  like  :  If  that  is  what  you  were  looking  for  .

code statement(s):
Sort sort=new Sort(SortField.FIELD_SCORE,sortField);


****************************** #365 ******************************
StackOverflow URL: https://stackoverflow.com/questions/16992828

comment sentences(s):
Before  executing  the  query  on  the  server  ,  the  client  would  not  know  about  what  you  have  set  on  the  server  side  ,  right  ?

code statement(s):
solrServer.query(solrQuery)

****************************** #366 ******************************
StackOverflow URL: https://stackoverflow.com/questions/16967100

comment sentences(s):
You  are  adding  the  entire  query  as  a  single  term  to  your  PhraseQuery  .

code statement(s):
phrase.add(new Term("textfield","name"))
phrase.add(new Term("textfield","website"))

****************************** #367 ******************************
StackOverflow URL: https://stackoverflow.com/questions/16967100

comment sentences(s):
a  single  term

code statement(s):
add(new Term("textfield","name"))
add(new Term("textfield","website"))

****************************** #368 ******************************
StackOverflow URL: https://stackoverflow.com/questions/16967100

comment sentences(s):
You  are  on  the  right  track  ,  but  when  tokenized  ,  that  will  not  be  a  single  term  ,  but  rather  two  .

code statement(s):
add(new Term("textfield","website"))

****************************** #369 ******************************
StackOverflow URL: https://stackoverflow.com/questions/16967100

comment sentences(s):
That  is  ,  your  index  has  the  terms  <em>  name  </em>  ,  <em>  website  </em>  ,  and  <em>  stackoverflow  </em>  ,  but  your  query  only  has  one  term  ,  which  matches  none  of  those  <em>  name  website  </em>  .

code statement(s):
add(new Term("textfield","name"))
add(new Term("textfield","website"))

****************************** #370 ******************************
StackOverflow URL: https://stackoverflow.com/questions/16373622

comment sentences(s):
The  source  for  MMapDirectory  shows  that  this  class  does  not  use  memory-mapped  files  ,  as  expected  .

code statement(s):
fsDirectory=FSDirectory.Open(directoryInfo)

****************************** #371 ******************************
StackOverflow URL: https://stackoverflow.com/questions/22936018

comment sentences(s):
the  IndexReader  ,  you  can  help  yourself  by  writing  This  will  ensure  no  result  is  omitted  from  the  search  .

code statement(s):
results=searcher.search(query,reader.NumDocs())

****************************** #372 ******************************
StackOverflow URL: https://stackoverflow.com/questions/22837132

comment sentences(s):
It  seems  that  solr  container  was  not  initialized  .

code statement(s):
EmbeddedSolrServer server=new EmbeddedSolrServer(container,"collection1");


****************************** #373 ******************************
StackOverflow URL: https://stackoverflow.com/questions/22456030

comment sentences(s):
However  ,  my  solution  is  to  split  the  string  before  I  feed  Lucene  with  it  .

code statement(s):
for(String part : input.split("\\p{Punct}"))

****************************** #374 ******************************
StackOverflow URL: https://stackoverflow.com/questions/21483283

comment sentences(s):
The  issue  was  related  to  the  Index  Crawler  padding  the  data  to  10  characters  with  the  following  :  I  changed  it  to  ToLexographical ( transformation  ,  4 ) which  results  in  a  4  character  string ( ex  -  4500 ) .

code statement(s):
result=ToLexographical(transformation,10)

****************************** #375 ******************************
StackOverflow URL: https://stackoverflow.com/questions/21349646

comment sentences(s):
Use  this  :  When  you  want  to  index  a  string  containing  multiple  words  ,  e.g.  ``  two  words  ''  as  one  searchable  element  without  tokenizing  into  2  words  ,  you  either  need  to  use  the  KeywordAnalyzer  during  indexing  which  takes  the  whole  string  as  a  token  or  you  can  use  the  StringField  object  in  newer  versions  of  Lucene  .

code statement(s):
new Field("FIELD2","string2",Field.Store.YES,Field.Index.TOKENIZED)

****************************** #376 ******************************
StackOverflow URL: https://stackoverflow.com/questions/21195662

comment sentences(s):
every  store  should  be  saved  in  a  different  document  ,  so  you  end  up  doing  something  like  :

code statement(s):
doc.add(new TextField("store",store,Field.Store.YES))

****************************** #377 ******************************
StackOverflow URL: https://stackoverflow.com/questions/21195662

comment sentences(s):
saved  in  a  different  document  ,  so  you  end  up  doing  something  like

code statement(s):
doc.add(new TextField("productName",product.name,Field.Store.YES))
doc.add(new FloatField("price",price,Field.Store.YES))
doc.add(new TextField("store",store,Field.Store.YES))
doc.add(new TextField("location",location,Field.Store.YES))

****************************** #378 ******************************
StackOverflow URL: https://stackoverflow.com/questions/21028490

comment sentences(s):
This  would  be  a  better  way  to  index  multiValued  fields  per  document  Whenever  multiple  fields  with  the  same  name  appear  in  one  document  ,  both  the  inverted  index  and  term  vectors  will  logically  append  the  tokens  of  the  field  to  one  another  ,  in  the  order  the  fields  were  added  .

code statement(s):
new StringField("categories",cat,Field.Store.YES)

****************************** #379 ******************************
StackOverflow URL: https://stackoverflow.com/questions/21028490

comment sentences(s):
Your  field  ``  categories  ''  in  Document  D1  has  two  values  -  ``  foo  bar  ''  and  ``  foo  baz  ''  Now  if  you  were  to  do  a  phrase  query  ``  bar  foo  ''  D1  should  not  come  up  .

code statement(s):
new StringField("categories",cat,Field.Store.YES)

****************************** #380 ******************************
StackOverflow URL: https://stackoverflow.com/questions/21028490

comment sentences(s):
This  is  ensure  by  adding  an  extra  increment  between  two  values  of  the  same  field  .

code statement(s):
new StringField("categories",cat,Field.Store.YES)

****************************** #381 ******************************
StackOverflow URL: https://stackoverflow.com/questions/21028490

comment sentences(s):
If  you  yourself  concatenate  the  field  values  and  rely  on  the  analyzer  to  split  it  into  multiple  values  ``  bar  foo  ''  would  return  D1  which  would  be  incorrect  .

code statement(s):
new StringField("categories",cat,Field.Store.YES)

****************************** #382 ******************************
StackOverflow URL: https://stackoverflow.com/questions/20408074

comment sentences(s):
This  allows  the  final3  and  final4  token  streams  to  share  the  processing  done  by  source1  .

code statement(s):
TokenStream final3=new EntityDetect(sink1);

TokenStream final4=new URLDetect(sink2);


****************************** #383 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19453153

comment sentences(s):
</em>  Well  ,  the  good  news  is  that  the  latest  versions  of  Solr ( starting  with  4.3  or  4.4  ,  I  think ) allows  you  to  do  what  they  call  Atomic  Updates  .

code statement(s):
SolrInputDocument updateDocument=new SolrInputDocument();


****************************** #384 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19453153

comment sentences(s):
See  here  :  http://wiki.apache.org/solr/Atomic_Updates  From  the  coding  point  of  view  ,  it  as  if  you  were  only  updating  the  desired  field  .

code statement(s):
updateDocument.addField("id",2312312)
updateDocument.addField("stuffedAnimals",new HashMap(){
{
    put("add","pink fluffy flamingo");
  }
}
)

****************************** #385 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19453153

comment sentences(s):
What  you  can  do  is  :  Problem  with  this  is  performance  :  what  actually  happens  when  you  do  this  is  that  the  document  is  removed  and  re-added  entirely ( not  just  the  field ) .

code statement(s):
updateDocument.addField("id",2312312)
updateDocument.addField("stuffedAnimals",new HashMap(){
{
    put("add","pink fluffy flamingo");
  }
}
)

****************************** #386 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19453153

comment sentences(s):
the  new  field

code statement(s):
addField("stuffedAnimals",new HashMap(){
{
    put("add","pink fluffy flamingo");
  }
}
)

****************************** #387 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19453153

comment sentences(s):
If  you  're  using  Solr  4.4  or  earlier  you  need  to  declare  the  new  fields  in  the  schema.xml  file  .

code statement(s):
addField("stuffedAnimals",new HashMap(){
{
    put("add","pink fluffy flamingo");
  }
}
)

****************************** #388 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19453153

comment sentences(s):
Finally  ,  as  a  remark  for  both  questions  :  if  you  want  to  update  a  Solr  document  ,  make  sure  all  its  fields  are  marked  as  ``  stored  '' ( stored  =  true  in  schema.xml ) .

code statement(s):
SolrInputDocument updateDocument=new SolrInputDocument();


****************************** #389 ******************************
StackOverflow URL: https://stackoverflow.com/questions/19453153

comment sentences(s):
Since  a  partial  update  on  a  field  translates  into  Solr  removing  and  re-adding  the  document ( with  the  update  applied ) ,  if  certain  fields  are  not  stored  ,  Solr  wo  n't  know  what  value  to  put  in  them  after  the  update  .

code statement(s):
SolrInputDocument updateDocument=new SolrInputDocument();


****************************** #390 ******************************
StackOverflow URL: https://stackoverflow.com/questions/26101010

comment sentences(s):
Are  you  mixing  Hibernate  ORM  Criteria  queries  with  Hibernate  Search  queries  .

code statement(s):
QueryBuilder queryBuilder=searchFactory.buildQueryBuilder().forEntity(Contact.class).get();


****************************** #391 ******************************
StackOverflow URL: https://stackoverflow.com/questions/25660284

comment sentences(s):
I  got  the  solution  bool  operation  is  given  on  keyword  which  can  be  used  form  multiple  column  query

code statement(s):
org.apache.lucene.search.Query query=qb.bool().should(qb.keyword().onField("title").ignoreFieldBridge().matching(searchable).createQuery()).should(qb.keyword().onField("isbnNo").ignoreAnalyzer().matching(searchable).createQuery()).createQuery();


****************************** #392 ******************************
StackOverflow URL: https://stackoverflow.com/questions/25623584

comment sentences(s):
Using  Guava  appending  to  a  text  looks  like  :  Few  of  my  notes  :  <ul>  I  am  not  sure  if  your  log  entities  are  garbage  collected    It  is  not  clear  that  file  content  is  kept  in  memory    If  log  is  in  xml  format  ,  then  whole  XML  DOM  might  need  to  be  parsed  if  new  element  is  added    </ul>

code statement(s):
File to=new File("C:/Logs/log.txt");


****************************** #393 ******************************
StackOverflow URL: https://stackoverflow.com/questions/24607702

comment sentences(s):
I  used  following  code  to  get  the  NumberOfDocuments  in  my  SOLR  Cloud  Collection  .

code statement(s):
SolrDocumentList solrDocumentList=queryResponse.getResults();


****************************** #394 ******************************
StackOverflow URL: https://stackoverflow.com/questions/24370318

comment sentences(s):
Try  a  phrase  query ( see  section  5.1.2.4  in  the  hibernate  query  dsl ) instead

code statement(s):
Query query=queryBuilder.phrase().onField("path").sentence("SNO_NO_D6-11100").createQuery();


****************************** #395 ******************************
StackOverflow URL: https://stackoverflow.com/questions/24370318

comment sentences(s):
The  two  terms  will  still  be  separated  ,  but  since  it  is  a  phrase  query  it  will  search  for  the  two  separate  terms  occurring  consecutively

code statement(s):
Query query=queryBuilder.phrase().onField("path").sentence("SNO_NO_D6-11100").createQuery();


****************************** #396 ******************************
StackOverflow URL: https://stackoverflow.com/questions/23871384

comment sentences(s):
It  seems  Lucene  can  not  deserialize  short  values  from  field  FIELD_MY_RANK  when  it  was  added  as  NumericField  .

code statement(s):
Field rankFieldShort=new Field(FIELD_MY_RANK,Short.toString((short)myRank),Field.Store.NO,Field.Index.ANALYZED_NO_NORMS);


****************************** #397 ******************************
StackOverflow URL: https://stackoverflow.com/questions/23871384

comment sentences(s):
short  values

code statement(s):
new Field(FIELD_MY_RANK,Short.toString((short)myRank),Field.Store.NO,Field.Index.ANALYZED_NO_NORMS)

****************************** #398 ******************************
StackOverflow URL: https://stackoverflow.com/questions/23388770

comment sentences(s):
Open  an  IndexReaders  for  each  index  .

code statement(s):
IndexSearcher searcher=new IndexSearcher(multiReader);


****************************** #399 ******************************
StackOverflow URL: https://stackoverflow.com/questions/23388770

comment sentences(s):
indexing  separate  or  indexing  as  single  ?

code statement(s):
IndexSearcher searcher=new IndexSearcher(multiReader);


****************************** #400 ******************************
StackOverflow URL: https://stackoverflow.com/questions/30704831

comment sentences(s):
It  will  not  look  like  a  relational  database  table  ,  instead  Lucene  uses  the  inverted  index  and  cosine  similarity  formula  for  searching  of  any  search  words  .

code statement(s):
IndexWriterConfig iwConf=new IndexWriterConfig(Version.LUCENE_48,new KeywordAnalyzer());


****************************** #401 ******************************
StackOverflow URL: https://stackoverflow.com/questions/30704831

comment sentences(s):
To  better  understand  you  need  to  look  for  various  terminology  and  formula  to  be  used  in  lucene  ,  you  can  check  out  it  on  lucene  officially  website  ,  https://lucene.apache.org/core/3_5_0/scoring.html#Query%20Classes  To  index  data  you  need  to  make  use  of  the  Lucene  indexer  and  searcher  API  use  this  pseudo  code  for  indexing  :

code statement(s):
IndexWriterConfig iwConf=new IndexWriterConfig(Version.LUCENE_48,new KeywordAnalyzer());


****************************** #402 ******************************
StackOverflow URL: https://stackoverflow.com/questions/30522391

comment sentences(s):
You  can  use  query  parser  it  's  better  approach  in  lucene  to  add  document  and  I  used  this  to  create  index  in  many  projects  ,

code statement(s):
Add(new Field("Id",searchResult.Id,Field.Store.YES,Field.Index.ANALYZED_NO_NORMS))

****************************** #403 ******************************
StackOverflow URL: https://stackoverflow.com/questions/28610313

comment sentences(s):
If  you  <br>  need  scoring ( like  -LCB-  @link  FuzzyQuery  -RCB-  ,  use  -LCB-  @link  TopTermsScoringBooleanQueryRewrite  -RCB-  which  uses  a  priority  queue  to  only  collect  competitive  terms  and  not  hit  this  limitation  .

code statement(s):
setRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE)

****************************** #404 ******************************
StackOverflow URL: https://stackoverflow.com/questions/28113558

comment sentences(s):
Index-time  boosts  are  stored  in  the  field  's  norm  ,  and  both  StringField  and  FloatField  omit  norms  by  default  .

code statement(s):
myStringType.setOmitNorms(false)

****************************** #405 ******************************
StackOverflow URL: https://stackoverflow.com/questions/27847504

comment sentences(s):
After  you  have  added  the  fields  once  ,  all  you  need  to  do  is  change  the  field  values  ,  and  then  write  the  altered  document  to  the  index  ,  like  this  :

code statement(s):
Field field1=new TextField("field1",field1Value,Field.Store.YES);

Field field2=new StringField("field2",field2Value,Field.Store.YES);


****************************** #406 ******************************
StackOverflow URL: https://stackoverflow.com/questions/27204343

comment sentences(s):
This  seems  to  be  a  bug  in  Lucene.Net.Contrib.Spatial  in  <strong>  MakeDistanceValueSource  </strong>  method  ,  so  i  wrote  a  a  new  DistanceValueSource  class  that  can  fix  the  problem  ,  called  <strong>  DistanceReverseValueSource  </strong>  ,  you  can  find  the  source  for  class  in  :  https://gist.github.com/aokour/088cd6484bce5e95ba83  Here  is  my  updated  code  snippet  now  :  <  pre  class  =  ``  lang-cs  prettyprint-override  ''  >  Now  results  are  sorted  from  closest  to  farest  !

code statement(s):
ValueSourceFilter vsf=new ValueSourceFilter(new QueryWrapperFilter(spatialQuery),valueSource,0,distance);


****************************** #407 ******************************
StackOverflow URL: https://stackoverflow.com/questions/27204343

comment sentences(s):
Lucene.Net.Contrib.Spatial  in  <strong>  MakeDistanceValueSource  </strong>  method

code statement(s):
spatialArgs=new SpatialArgs(SpatialOperation.Intersects,ctx.MakeCircle(lng,lat,distance))
ValueSourceFilter vsf=new ValueSourceFilter(new QueryWrapperFilter(spatialQuery),valueSource,0,distance);


****************************** #408 ******************************
StackOverflow URL: https://stackoverflow.com/questions/27175315

comment sentences(s):
Filter  is  irrelevant  to  the  explanation  ,  <strong>  as  it  only  narrows  down  the  total  amount  of  hits  by  eliminating  documents  not  matching  the  filters  provided  </strong>  ,  and  not  by  changing  your  actual  query  .

code statement(s):
search(query,filter,10)

****************************** #409 ******************************
StackOverflow URL: https://stackoverflow.com/questions/27175315

comment sentences(s):
So  to  sum  it  up  ,  filters  have  no  impact  on  the  actual  explanation  of  a  specific  document  in  regards  to  the  query  performed  upon  it  .

code statement(s):
search(query,filter,10)

****************************** #410 ******************************
StackOverflow URL: https://stackoverflow.com/questions/27138074

comment sentences(s):
From  Graph  Api  you  can  not  change  the  Engine  .

code statement(s):
graph.getRawGraph().command(new OCommandSQL("create index V.name on V (name) FULLTEXT ENGINE LUCENE"))

****************************** #411 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34153573

comment sentences(s):
You  need  to  run  the  mass  indexer  to  add  all  those  entities  to  the  index  which  have  been  added/updated  while  Hibernate  Search  was  not ( yet ) enabled  .

code statement(s):
fullTextEntityManager.createIndexer(Entity.class)

****************************** #412 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34153573

comment sentences(s):
This  will  fetch  all  the  entities  from  the  database  und  update  the  corresponding  index ( es ) .

code statement(s):
fullTextEntityManager.createIndexer(Entity.class)

****************************** #413 ******************************
StackOverflow URL: https://stackoverflow.com/questions/32352475

comment sentences(s):
Basically  ,  you  need  a  token  from  the  user  and  check  ,  if  this  token  is  still  valid  with  the  LifetimeManager  ,  otherwise  you  create  a  new  token  with  a  new  IndexSearcher  from  the  SearcherManager  .

code statement(s):
manager.release(is)

****************************** #414 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31992782

comment sentences(s):
the  urls  in  two  separate  fields  :  url1  searchable ( indexed ) ,  and  url2  ,  just  stored

code statement(s):
new StringField("url1",url1String,Store.NO)

****************************** #415 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31961241

comment sentences(s):
Here  I  combine  whitespace  tokenization ( probably  you  could  replace  it  with  <strong>  StandardAnalyzer  </strong>  which  is  more  sophisticated ) and  then  I  remove  stop  words  with  <strong>  StopFilter  </strong>  and  later  in  analyzer  chain  use  a  <strong>  PorterStemFilter  </strong> ( which  also  more  better  than  just  simple  <strong>  EnglishStemmer  </strong>  ,  also  you  could  replace  it  with  any  <strong>  TokenFilter  </strong>  you  like  .

code statement(s):
TokenStream tokenStream=new StopFilter(whitespaceTokenizer,StopAnalyzer.ENGLISH_STOP_WORDS_SET);


****************************** #416 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31678500

comment sentences(s):
You  can  achieve  this  by  using  multiple  boolean  queries  .

code statement(s):
BooleanQuery finalQuery=new BooleanQuery();


****************************** #417 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31598837

comment sentences(s):
The  particular  reason  that  changing  the  boost  may  even  result  in  lower  scores  is  because  of  the  queryNorm  scoring  factor  .

code statement(s):
QueryBuilders.boolQuery.should(mltQuery.boost(50)).should(someOtherQueryBuilder)

****************************** #418 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31478192

comment sentences(s):
the  query  must  much  this  term ( like  AND  )

code statement(s):
Query luceneQuery=b.bool().must(b.keyword().onField("fieldName").matching("term1").createQuery()).must(b.keyword().onField("fieldName").matching("term2").createQuery()).should(b.keyword().onField("fieldName").matching("term3").createQuery()).except(b.keyword().onField("fieldName").matching("term4").createQuery()).createQuery();


****************************** #419 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31478192

comment sentences(s):
must  much  this  term ( like  AND  )

code statement(s):
b.bool().must(b.keyword().onField("fieldName").matching("term1").createQuery()).must(b.keyword().onField("fieldName").matching("term2").createQuery()).should(b.keyword().onField("fieldName").matching("term3").createQuery()).except(b.keyword().onField("fieldName").matching("term4").createQuery())

****************************** #420 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31478192

comment sentences(s):
should  :  the  query  should  this  query ( like  OR ) .

code statement(s):
Query luceneQuery=b.bool().must(b.keyword().onField("fieldName").matching("term1").createQuery()).must(b.keyword().onField("fieldName").matching("term2").createQuery()).should(b.keyword().onField("fieldName").matching("term3").createQuery()).except(b.keyword().onField("fieldName").matching("term4").createQuery()).createQuery();


****************************** #421 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31478192

comment sentences(s):
except  :  to  exclude  the  document  that  contains  this  term ( like  NOT ) .

code statement(s):
b.bool().must(b.keyword().onField("fieldName").matching("term1").createQuery()).must(b.keyword().onField("fieldName").matching("term2").createQuery()).should(b.keyword().onField("fieldName").matching("term3").createQuery()).except(b.keyword().onField("fieldName").matching("term4").createQuery())

****************************** #422 ******************************
StackOverflow URL: https://stackoverflow.com/questions/35732401

comment sentences(s):
Indexed  ,  unstored  fields  can  be  searched  ,  but  wo  n't  be  returned  with  results  .

code statement(s):
new TextField("mytext","some text",Field.Store.YES)

****************************** #423 ******************************
StackOverflow URL: https://stackoverflow.com/questions/35678256

comment sentences(s):
I  have  a  <strong>  Lucene.NET  3.0.3  solution  which  allows  spatial  search  with  ordering  </strong> ( from  a  centre  point ) ,  within  a  circle  of  a  given  radius  .

code statement(s):
spatialArgs=new SpatialArgs(SpatialOperation.Intersects,searchArea)

****************************** #424 ******************************
StackOverflow URL: https://stackoverflow.com/questions/35678256

comment sentences(s):
The  key  portion  of  code  which  drives  the  spatial  search  is  this  :  Please  let  me  know  if  anything  is  unclear  .

code statement(s):
spatialArgs=new SpatialArgs(SpatialOperation.Intersects,searchArea)

****************************** #425 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34153573

comment sentences(s):
You  need  to  run  the  mass  indexer  to  add  all  those  entities  to  the  index  which  have  been  added/updated  while  Hibernate  Search  was  not ( yet ) enabled  .

code statement(s):
fullTextEntityManager.createIndexer(Entity.class)

****************************** #426 ******************************
StackOverflow URL: https://stackoverflow.com/questions/34153573

comment sentences(s):
This  will  fetch  all  the  entities  from  the  database  und  update  the  corresponding  index ( es ) .

code statement(s):
fullTextEntityManager.createIndexer(Entity.class)

****************************** #427 ******************************
StackOverflow URL: https://stackoverflow.com/questions/32352475

comment sentences(s):
Basically  ,  you  need  a  token  from  the  user  and  check  ,  if  this  token  is  still  valid  with  the  LifetimeManager  ,  otherwise  you  create  a  new  token  with  a  new  IndexSearcher  from  the  SearcherManager  .

code statement(s):
manager.release(is)

****************************** #428 ******************************
StackOverflow URL: https://stackoverflow.com/questions/32352475

comment sentences(s):
need  a  token  from  the  user  and  check

code statement(s):
tokenToReturn=mgr.record(is)
tokenToReturn=mgr.record(is)

****************************** #429 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31992782

comment sentences(s):
At  index  time  ,  it  is  possible  to  add  the  urls  in  two  separate  fields  :  url1  searchable ( indexed ) ,  and  url2  ,  just  stored  .

code statement(s):
add(new StringField("url1",url1String,Store.NO))

****************************** #430 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31961241

comment sentences(s):
Here  I  combine  whitespace  tokenization ( probably  you  could  replace  it  with  <strong>  StandardAnalyzer  </strong>  which  is  more  sophisticated ) and  then  I  remove  stop  words  with  <strong>  StopFilter  </strong>  and  later  in  analyzer  chain  use  a  <strong>  PorterStemFilter  </strong> ( which  also  more  better  than  just  simple  <strong>  EnglishStemmer  </strong>  ,  also  you  could  replace  it  with  any  <strong>  TokenFilter  </strong>  you  like  .

code statement(s):
TokenStream tokenStream=new StopFilter(whitespaceTokenizer,StopAnalyzer.ENGLISH_STOP_WORDS_SET);


****************************** #431 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31598837

comment sentences(s):
The  particular  reason  that  changing  the  boost  may  even  result  in  lower  scores  is  because  of  the  queryNorm  scoring  factor  .

code statement(s):
QueryBuilders.boolQuery.should(mltQuery.boost(50)).should(someOtherQueryBuilder)

****************************** #432 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31478192

comment sentences(s):
the  query  must  much  this  term ( like  AND  )

code statement(s):
Query luceneQuery=b.bool().must(b.keyword().onField("fieldName").matching("term1").createQuery()).must(b.keyword().onField("fieldName").matching("term2").createQuery()).should(b.keyword().onField("fieldName").matching("term3").createQuery()).except(b.keyword().onField("fieldName").matching("term4").createQuery()).createQuery();


****************************** #433 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31478192

comment sentences(s):
must  much  this  term ( like  AND  )

code statement(s):
b.bool().must(b.keyword().onField("fieldName").matching("term1").createQuery()).must(b.keyword().onField("fieldName").matching("term2").createQuery()).should(b.keyword().onField("fieldName").matching("term3").createQuery()).except(b.keyword().onField("fieldName").matching("term4").createQuery())

****************************** #434 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31478192

comment sentences(s):
should  :  the  query  should  this  query ( like  OR ) .

code statement(s):
Query luceneQuery=b.bool().must(b.keyword().onField("fieldName").matching("term1").createQuery()).must(b.keyword().onField("fieldName").matching("term2").createQuery()).should(b.keyword().onField("fieldName").matching("term3").createQuery()).except(b.keyword().onField("fieldName").matching("term4").createQuery()).createQuery();


****************************** #435 ******************************
StackOverflow URL: https://stackoverflow.com/questions/31478192

comment sentences(s):
except  :  to  exclude  the  document  that  contains  this  term ( like  NOT ) .

code statement(s):
b.bool().must(b.keyword().onField("fieldName").matching("term1").createQuery()).must(b.keyword().onField("fieldName").matching("term2").createQuery()).should(b.keyword().onField("fieldName").matching("term3").createQuery()).except(b.keyword().onField("fieldName").matching("term4").createQuery())

